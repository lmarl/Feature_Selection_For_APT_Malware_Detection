################################################
#
# This script trains the provided dataset using 4 different classifiers (KNN, Linear SVM, Logistic
# Regression and Random Forest. And obtains a result table that is later provided as Table 4 in i
# the paper.
#
# This script receives a parameter. Value 1 will show the Classifier training data while value 2 will show the AUC curves of
# each classifier
#
# Author: Luis Martin Liras
#
################################################


################################################
#     IMPORTS
################################################
import numpy as np
from numpy import *
import pandas as pd
from time import time
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn import manifold
from sklearn.manifold import TSNE
from sklearn.externals import joblib
from sklearn.linear_model import LogisticRegression
import sys
import os
import time
import warnings
###KNN###########
from sklearn import neighbors, datasets
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score
###SVM##########
from sklearn import svm
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
###AUC###########
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import classification_report


##################################
# ARGUMENTS
##################################
def syntax_error():
        print "SYNTAX ERROR: Introduce dos argumentos con los siguientes valores"
        print "Primer argumento:"
        print " 1 Show experiment data"
        print " 2 Show AUC Plot"

argumentos=sys.argv
if len(argumentos)!=2:
        syntax_error()
        sys.exit()
else:
        if (argumentos[1]!='1' and argumentos[1]!='2'):
                syntax_error()
                sys.exit()

##################################
# CONFIGURATION
##################################
warnings.simplefilter(action='ignore', category=FutureWarning)

input_file = "../datasets/reducido_a_1941_features_without_NaNs_y_19457_rows.csv"

os.system("clear")

##################################
# PRELIMINAR TASKS
##################################
###Read dataset
df = pd.read_csv(input_file, header = 0, sep=';')

##Extract target fields
isapt=df.APT
valuesAPT=isapt.values.astype(np.int64)

del df["APT"]
del df["ID"]

if argumentos[1]>0:
    df1=df[['ALL_FILES_C:','ALL_FILES_C:/Program_Files','ALL_FILES_C:/Program_Files/Internet_Explorer','ALL_FILES_C:/WINDOWS/system32','ALL_FILES_C:/WINDOWS/system32/drivers','ANTIDEBUG_FindWindowA','ANTIDEBUG_FindWindowExA','ANTIDEBUG_FindWindowExW','ANTIDEBUG_GetWindowThreadProcessId','ANTIDEBUG_%IsDebuggerPresent','ANTIDEBUG_OutputDebugStringA','ANTIDEBUG_Process32First','ANTIDEBUG_Process32Next','ANTIDEBUG_TerminateProcess','ANTIDEBUG_UnhandledExceptionFilter','DELETED_FILES_C:','DELETED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','DNS_CN','DNS_NL','DNS_US','HAS_OVERLAYS','IMPORTS_BIN_CloseHandle','IMPORTS_BIN_CopyFile','IMPORTS_BIN_CreateDirectoryA','IMPORTS_BIN_CreateFile','IMPORTS_BIN_CreateFileMapping','IMPORTS_BIN_CreateMutex','IMPORTS_BIN_CreateProcessA','IMPORTS_BIN_CreateWindowExA','IMPORTS_BIN_DeleteCriticalSection','IMPORTS_BIN_DeleteFile','IMPORTS_BIN_DeleteObject','IMPORTS_BIN_DispatchMessageA','IMPORTS_BIN_EnterCriticalSection','IMPORTS_BIN_ExitProcess','IMPORTS_BIN_FileSize','IMPORTS_BIN_FindClose','IMPORTS_BIN_FindFirstFile','IMPORTS_BIN_FindNextFile','IMPORTS_BIN_FindResource','IMPORTS_BIN_FindWindow','IMPORTS_BIN_FreeLibrary','IMPORTS_BIN_GetACP','IMPORTS_BIN_GetCPInfo','IMPORTS_BIN_GetCurrentProcess','IMPORTS_BIN_GetCurrentProcessId','IMPORTS_BIN_GetCurrentThreadId','IMPORTS_BIN_GetDC','IMPORTS_BIN_GetDeviceCaps','IMPORTS_BIN_GetDlgItem','IMPORTS_BIN_GetFileAttributes','IMPORTS_BIN_GetFileAttributesA','IMPORTS_BIN_GetFileTime','IMPORTS_BIN_GetFileType','IMPORTS_BIN_GetFullPathName','IMPORTS_BIN_GetLastError','IMPORTS_BIN_GetShortPathName','IMPORTS_BIN_GetStdHandle','IMPORTS_BIN_GetSystemDirectoryA','IMPORTS_BIN_GetTempFileName','IMPORTS_BIN_GetTempPathA','IMPORTS_BIN_GetVersion','IMPORTS_BIN_GetWindowsDirectory','IMPORTS_BIN_GlobalAlloc','IMPORTS_BIN_GlobalFree','IMPORTS_BIN_GlobalLock','IMPORTS_BIN_GlobalUnlock','IMPORTS_BIN_HeapAlloc','IMPORTS_BIN_HeapFree','IMPORTS_BIN_InitializeCriticalSection','IMPORTS_BIN_InternetOpen','IMPORTS_BIN_IsDebuggerPresent','IMPORTS_BIN_IsWindow','IMPORTS_BIN_LeaveCriticalSection','IMPORTS_BIN_LoadLibrary','IMPORTS_BIN_LoadResource','IMPORTS_BIN_lstrcpynA','IMPORTS_BIN_lstrlenA','IMPORTS_BIN_MapViewOfFile','IMPORTS_BIN_MessageBoxA','IMPORTS_BIN_MoveFile','IMPORTS_BIN_MultiByteToWideChar','IMPORTS_BIN_OpenFile','IMPORTS_BIN_PostQuitMessage','IMPORTS_BIN_RaiseException','IMPORTS_BIN_ReadFile','IMPORTS_BIN_RegCloseKey','IMPORTS_BIN_RegCreateKey','IMPORTS_BIN_RegOpenKey','IMPORTS_BIN_RegQueryValueExA','IMPORTS_BIN_RegSetValue','IMPORTS_BIN_RegSetValueExA','IMPORTS_BIN_RtlUnwind','IMPORTS_BIN_SelectObject','IMPORTS_BIN_SetErrorMode','IMPORTS_BIN_SetFileAttributes','IMPORTS_BIN_SetFilePointer','IMPORTS_BIN_SetFileTime','IMPORTS_BIN_ShowWindow','IMPORTS_BIN_TlsGetValue','IMPORTS_BIN_TlsSetValue','IMPORTS_BIN_WaitForSingleObject','IMPORTS_BIN_WideCharToMultiByte','IMPORTS_BIN_wsprintfA','isOtherType','isRootkit','isSpyware','isTrojan','isTypeUnknown','isWorm','NUM_IMPORTS','NUM_PACKERS','OPENED_FILES_//.','OPENED_FILES_C:','OPENED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','OPENED_FILES_C:/Program_Files','OPENED_FILES_C:/Program_Files/Internet_Explorer','OPENED_FILES_C:/WINDOWS','OPENED_FILES_C:/WINDOWS/Registration','OPENED_FILES_C:/WINDOWS/system32','OPENED_FILES_C:/WINDOWS/system32/drivers','OPENED_FILES_//./PIPE','PACKER_Armadillo','PACKER_BobSoft','PACKER_MSLRH','PACKER_NullSoft','PACKER_UPX','READ_FILES_C:','READ_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','READ_FILES_C:/Program_Files/Internet_Explorer','READ_FILES_C:/WINDOWS/Registration','READ_FILES_C:/WINDOWS/system32','RESOURCE_NUM','SERVICES_AudioSrv','SERVICES_RASMAN','SERVICES_RemoteAccess','SERVICES_Router','SUSP_API_ConnectNamedPipe','SUSP_API_CopyFileA','SUSP_API_CreateDirectoryW','SUSP_API_CreateFileA','SUSP_API_CreateFileMappingA','SUSP_API_CreateFileW','SUSP_API_CreateProcessW','SUSP_API_CreateServiceA','SUSP_API_CreateThread','SUSP_API_CreateToolhelp32Snapshot','SUSP_API_DeleteFileA','SUSP_API_DeleteFileW','SUSP_API_ExitThread','SUSP_API_FindFirstFileA','SUSP_API_FindFirstFileW','SUSP_API_FindNextFileA','SUSP_API_FindNextFileW','SUSP_API_FindResourceA','SUSP_API_FindResourceW','SUSP_API_FindWindowA','SUSP_API_FindWindowExW','SUSP_API_GetCommandLineA','SUSP_API_GetCommandLineW','SUSP_API_GetComputerNameA','SUSP_API_GetDriveTypeA','SUSP_API_GetFileAttributesExA','SUSP_API_GetFileAttributesW','SUSP_API_GetFileSize','SUSP_API_GetModuleFileNameA','SUSP_API_GetModuleFileNameW','SUSP_API_GetModuleHandleA','SUSP_API_GetModuleHandleW','SUSP_API_GetProcAddress','SUSP_API_GetStartupInfoA','SUSP_API_GetStartupInfoW','SUSP_API_GetTempFileNameA','SUSP_API_GetTickCount','SUSP_API_GetUserNameA','SUSP_API_GetVersionExA','SUSP_API_GetVersionExW','SUSP_API_GetWindowThreadProcessId','SUSP_API_HttpQueryInfoA','SUSP_API_HttpSendRequestA','SUSP_API_InternetCloseHandle','SUSP_API_InternetConnectA','SUSP_API_InternetOpenA','SUSP_API_InternetReadFile','SUSP_API_LoadLibraryA','SUSP_API_LoadLibraryExA','SUSP_API_LoadLibraryW','SUSP_API_LockResource','SUSP_API_OpenProcess','SUSP_API_OpenProcessToken','SUSP_API_OutputDebugStringA','SUSP_API_Process32First','SUSP_API_Process32Next','SUSP_API_RegCreateKeyExA','SUSP_API_RegCreateKeyExW','SUSP_API_RegDeleteKeyA','SUSP_API_RegDeleteValueA','SUSP_API_RegEnumKeyA','SUSP_API_RegEnumKeyExA','SUSP_API_RegOpenKeyA','SUSP_API_RegOpenKeyExA','SUSP_API_RegOpenKeyExW','SUSP_API_SetWindowsHookExA','SUSP_API_ShellExecuteA','SUSP_API_ShellExecuteExA','SUSP_API_Sleep','SUSP_API_StartServiceA','SUSP_API_VirtualAlloc','SUSP_API_VirtualAllocEx','SUSP_API_VirtualFree','SUSP_API_VirtualProtect','SUSP_API_WinExec','SUSP_API_WriteFile','SUSP_DLLS_ADVAPI32.dll','SUSP_DLLS_COMCTL32.DLL','SUSP_DLLS_comdlg32.dll','SUSP_DLLS_DLL_EN_BLANCO','SUSP_DLLS_GDI32.DLL','SUSP_DLLS_HAL.dll','SUSP_DLLS_KERNEL32','SUSP_DLLS_KERNEL32.dll','SUSP_DLLS_Msvcrt.dll','SUSP_DLLS_ntoskrnl.exe','SUSP_DLLS_OLE32.DLL','SUSP_DLLS_OLEAUT32.DLL','SUSP_DLLS_Shell32.dll','SUSP_DLLS_SHLWAPI.dll','SUSP_DLLS_URLMON.DLL','SUSP_DLLS_USER32.dll','SUSP_DLLS_version.dll','SUSP_DLLS_wininet.dll','SUSP_DLLS_WINMM.DLL','SUSP_DLLS_WINSPOOL.DRV','SUSP_DLLS_ws2_32.dll','SUSP_DLLS_WSOCK32.DLL','TCP_US','UDP_NL','UDP_US']]
    df=df1
else:
    del df["NUM_APT"]



#Using 100% of the dataset...
#66% por training:
num_trn=13000 #66,8%
#And 33% for testing:
num_tes=6457 #33,2%

#If we'd use %66%...
#num_trn=8475
#num_tes=4365

#If we'd use %33%...
#num_trn=4237
#num_tes=2182

##################################
# Prepare Training y Testing sets
##################################
#
#Shuffle the samples (Actually shuffling indexes). 
shuffle_index=np.random.permutation(num_trn)

#Nos quedamos con los valores, descartando las cabeceras
df3=df.values
df=df.values

###########
#X_train son las 13000 primeras muestras. X_test son las 3547 ultimas muestras
#Y_train es un 0 o un 1 por cada una de esas 17000 muestras indicando si se trata de un APT o no
#Y_test es un 0 o un 1 por cada una de esas 3547 muestras indicando si se trata de un APT o no
#X_train,X_test,Y_train,Y_test=df[:17000],df[17000:],isapt[:17000],isapt[17000:]
X_train,X_test,Y_train,Y_test=df[:num_trn],df[num_trn:num_trn+num_tes],isapt[:num_trn],isapt[num_trn:num_trn+num_tes]

#############
#Calculamos un test set con el mismo numero de malware que de APTs
total=200
numAPT=0
numMAL=0
XequalSet=[]
YequalSet=pd.Series()
numTotal=1

for i in range(1,num_trn+num_tes):
        if numAPT<total and valuesAPT[i]>0:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, valuesAPT[i])
                numAPT+=1
                numTotal+=1

        if numMAL<total and valuesAPT[i]==0:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, valuesAPT[i])
                numMAL+=1
                numTotal+=1

        if numAPT>=total and numMAL>=total:
                break

XequalSet = np.array(XequalSet)

#Al final en Xequalset y en YEqualset hay 400 muestras, 200 son APTs y 200 son malware generico

###########################################
# TARGET VECTORS
###########################################
#Pasamos de valores 0 o 1 a valores true or false:
Y_train_APT=(Y_train == 1)
Y_test_APT=(Y_test == 1)

print ("################################################")
print ("            KNN")
print ("################################################")

###########################################
# KNN
###########################################

####TIMING#########
start2=time.time()
knn_clf = neighbors.KNeighborsClassifier(n_neighbors=2)
knn_clf.fit(X_train, Y_train_APT)
end2=time.time()
KNN_train_time=end2-start2
###################

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(num_trn,num_trn+num_tes):
        total=total+1
        ej=df3[i]
        prediction=knn_clf.predict([ej])

        if (prediction) and valuesAPT[i]==1:
                acierto=acierto + 1
        if (not prediction) and valuesAPT[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(knn_clf, X_test, Y_test_APT)

#En y_test_pred se ha almacenado el array de predicciones
#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(knn_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

# Confusion Matrix
####################
print "\nConfusion Matrix"
KNN_cm=confusion_matrix(Y_test_APT,y_test_pred)
print KNN_cm

# Accuracy
###########
KNN_Acc=1.0* (KNN_cm[0][0]+KNN_cm[1][1])/ num_tes
print "\nAccuracy: ", KNN_Acc

# Prec
###########
KNN_pr=precision_score(Y_test_APT,y_test_pred)
print "\nPrecision Score:", KNN_pr

# Recall
###########
KNN_r=recall_score(Y_test_APT,y_test_pred)
print "\nRecall Score:", KNN_r

# F1
###########
KNN_f1=2*KNN_pr*KNN_r/(KNN_pr+KNN_r)
print "\nF1:", KNN_f1

# FNR
###########
KNN_FNR=1-KNN_r
print "\nFNR:", KNN_FNR

# AUC
############
##Lo fiteamos contra los datos de training
knn_clf = neighbors.KNeighborsClassifier(n_neighbors=2)
fitted_knn_clf=knn_clf.fit(X_train, Y_train_APT)

y_probabilities_knn=cross_val_predict(fitted_knn_clf, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_knn=y_probabilities_knn[:,1]

#y_scores_knn = fitted_knn_clf.decision_function(X_test)
fpr_knn, tpr_knn, threshold_knn=roc_curve(Y_test_APT,y_scores_knn)
KNN_roc_auc = auc(fpr_knn, tpr_knn)

print "ROC AUC: ", KNN_roc_auc
print
print ("################################################")
print ("            Linear SVM")
print ("################################################")
###########################################
# SVM (Linear)
###########################################

##TIMING#################
start2=time.time()
svm_clf = svm.LinearSVC(C=0.01)
svm_clf.fit(X_train, Y_train_APT)
end2=time.time()
SVM_train_time=end2-start2
###################

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
#for i in range(17000,20529):
for i in range(num_trn,num_trn+num_tes):
        total=total+1
        ej=df3[i]
        prediction=svm_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and valuesAPT[i]==1:
                acierto=acierto + 1
        if (not prediction) and valuesAPT[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(svm_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones
#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(svm_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

####################
# Confusion Matrix
####################
SVM_cm=confusion_matrix(Y_test_APT,y_test_pred)
print "\nConfusion Matrix"
print SVM_cm

# Accuracy
###########
SVM_Acc=1.0* (SVM_cm[0][0]+SVM_cm[1][1])/ num_tes
print "\nAccuracy: ", SVM_Acc
# Prec
###########
SVM_pr=precision_score(Y_test_APT,y_test_pred)
print "\nPrecision Score: ", SVM_pr
# Recall
###########
SVM_r=recall_score(Y_test_APT,y_test_pred)
print "\nRecall Score:", SVM_r
# F1
###########
SVM_f1=2*SVM_pr*SVM_r/(SVM_pr+SVM_r)
print "\nF1: ",SVM_f1
# FNR
###########
SVM_FNR=1-SVM_r
print "\nFNR:", SVM_FNR

#  AUC
##########
#
y_probabilities_svm=cross_val_predict(svm_clf, X_train, Y_train_APT, cv=10)
#print y_probabilities_svm
#y_scores_svm=y_probabilities_svm[:,1]
#SVM_auc=roc_auc_score(Y_train_APT, y_scores_svm)
#fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_train_APT,y_scores_svm)
#
#plt.plot(fpr_svm, tpr_svm, linewidth=2, label=None)
#

##Lo fiteamos contra los datos de training
svm_clf = svm.SVC(C=0.01)
fitted_svm_clf=svm_clf.fit(X_train, Y_train_APT)

#y_probabilities_svm=cross_val_predict(fitted_svm_clf, X_train, Y_train_APT, cv=7,method="predict_proba")
#print y_probabilities_svm

##las probabilidades las sacamos contra los datos de testing
y_scores_svm = fitted_svm_clf.decision_function(X_test)
fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_test_APT,y_scores_svm)
SVM_roc_auc = auc(fpr_svm, tpr_svm)
print "ROC AUC: ", SVM_roc_auc
print
print ("################################################")
print ("            LOGISTIC REGRESSION")
print ("################################################")

###############################################
# LOGISTIC REGRESSION
##############################################

#####TIMING##############
start2=time.time()
lr_clf = LogisticRegression()
fitted_lr_clf=lr_clf.fit(X_train, Y_train_APT)
end2=time.time()
LOG_train_time=end2 - start2
########################

##Obtain predictions and calculate % of correct predictions in test set.
acierto=0
total=0
for i in range(num_trn,num_trn+num_tes):
        total=total+1
        ej=df3[i]
        prediction=fitted_lr_clf.predict([ej])

        if (prediction) and valuesAPT[i]==1:
                acierto=acierto + 1
        if (not prediction) and valuesAPT[i]==0:
                acierto=acierto + 1

media=0.0
media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(fitted_lr_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(fitted_lr_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
LOG_cm=confusion_matrix(Y_test_APT,y_test_pred)
print LOG_cm

# Accuracy
###########
LOG_Acc= 1.0* (LOG_cm[0][0] + LOG_cm[1][1])/ num_tes
print "\nAccuracy: ",LOG_Acc

# Precission
###########
LOG_pr=precision_score(Y_test_APT,y_test_pred)
print "\nPrecision Score: ", LOG_pr

# Recall
###########
LOG_r=recall_score(Y_test_APT,y_test_pred)
print "\nRecall Score: ", LOG_r

# F1
###########
LOG_f1=2*LOG_pr*LOG_r/(LOG_pr+LOG_r)
print "\nF1: ", LOG_f1

# FNR
###########
LOG_FNR=1-LOG_r
print "\nFNR: ",LOG_FNR

######LOGISTIC REGRESSION########
lr_clf = LogisticRegression()
fitted_lr_clf=lr_clf.fit(X_train, Y_train_APT)

lr_predict_probabilities = fitted_lr_clf.predict_proba(X_test)[:,1]

fpr_lr, tpr_lr, threshold_lr = roc_curve(Y_test_APT, lr_predict_probabilities)
LOG_roc_auc = auc(fpr_lr, tpr_lr)

print
print ("################################################")
print ("             RANDOM FOREST")
print ("################################################")


###########################################
# Random Forest Classifier
###########################################
from sklearn.ensemble import RandomForestClassifier

###TIMING ###################
#Creamos el clasificador. El random_state value no deberia afectar
start2=time.time()
forest_clf = RandomForestClassifier(random_state=42,n_estimators=100)
forest_clf.fit(X_train, Y_train_APT)
end2=time.time()
RAN_train_time=end2-start2
#######################

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(num_trn,num_trn+num_tes):
        total=total+1
        ej=df3[i]
        prediction=forest_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and valuesAPT[i]==1:
                acierto=acierto + 1
        if (not prediction) and valuesAPT[i]==0:
                acierto=acierto + 1

media=0.0
media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(forest_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(forest_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100
###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
RAN_cm=confusion_matrix(Y_test_APT,y_test_pred)
print RAN_cm

# Accuracy
###########
RAN_Acc=1.0* (RAN_cm[0][0] + RAN_cm[1][1])/ num_tes
print "\nAccuracy: ", RAN_Acc

# Precission
###########
RAN_pr=precision_score(Y_test_APT,y_test_pred)
print "\nPrecision Score: ", RAN_pr

# Recall
###########
RAN_r=recall_score(Y_test_APT,y_test_pred)
print "\nRecall Score: ", RAN_r

# F1
###########
RAN_f1=2*RAN_pr*RAN_r/(RAN_pr+RAN_r)
print "\nF1: ", RAN_f1

# FNR
###########
RAN_FNR=1-RAN_r
print "\nFNR: ", RAN_FNR

# ROC AUC (Area under Curve) Score
###########
y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")
y_scores_forest=y_probabilities_forest[:,1]
RAN_roc_auc=roc_auc_score(Y_train_APT, y_scores_forest)
print "\nAUC: ", RAN_roc_auc


###########
# Classification Report
###########
#print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))


##########
# ROC Curve
#
# Esta grafica nos permite decidir cual de los clasificadores son mejores
###########

#Aqui Obtenemos probabilidades, a partir de los sets de training de cada clase
#y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")

#Esto devuelve un array del tipo( Probabilidades de que si, probabilidades de que no):
#[[1.  0. ]
# [1.  0. ]
# ...
# [0.7 0.3]
# [0.6 0.4]
# [0.  1. ]]

#
#######RANDOM FOREST########
y_scores_forest=y_probabilities_forest[:,1]
fpr_forest, tpr_forest, threshold_forest=roc_curve(Y_train_APT,y_scores_forest)
roc_auc = auc(fpr_forest, tpr_forest)
#


#


if (argumentos[1]=='1'):
    print ("################################################")
    print ("             FINAL TABLE")
    print ("################################################")
    ###########################################
    # FINAL TABLE
    ###########################################
    
    print
    print "##############################################################################################"
    print ("Algorithms     -- TP  --  FP  --  TN  --  FN  --  FNR  --  Prec  -- Recall --  F1  --  Acc.  --  AUC  --  Time");
    print  "KNN            --",KNN_cm[1][1],"--",KNN_cm[0][1],"--", KNN_cm[0][0],"--",KNN_cm[1][0],"--{0:.4f}".format(KNN_FNR),"--{0:.4f}".format(KNN_pr),"--{0:.4f}".format(KNN_r),"--{0:.4f}".format(KNN_f1),"--{0:.4f}".format(KNN_Acc),"-- {0:.4f}".format(KNN_roc_auc),"--",KNN_train_time
    print "LOG. REGRESSION --",LOG_cm[1][1],"--",LOG_cm[0][1],"--", LOG_cm[0][0],"--",LOG_cm[1][0],"--{0:.4f}".format(LOG_FNR),"--{0:.4f}".format(LOG_pr),"--{0:.4f}".format(LOG_r),"--{0:.4f}".format(LOG_f1),"--{0:.4f}".format(LOG_Acc),"-- {0:.4f}".format(LOG_roc_auc)," --",LOG_train_time
    print "SVM             --",SVM_cm[1][1],"--",SVM_cm[0][1],"--", SVM_cm[0][0],"--",SVM_cm[1][0],"--{0:.4f}".format(SVM_FNR),"--{0:.4f}".format(SVM_pr),"--{0:.4f}".format(SVM_r),"--{0:.4f}".format(SVM_f1),"--{0:.4f}".format(SVM_Acc),"-- {0:.4f}".format(SVM_roc_auc)," --",SVM_train_time
    print "RANDOM FOREST   --",RAN_cm[1][1],"--",RAN_cm[0][1],"--", RAN_cm[0][0],"--",RAN_cm[1][0],"--{0:.4f}".format(RAN_FNR),"--{0:.4f}".format(RAN_pr),"--{0:.4f}".format(RAN_r),"--{0:.4f}".format(RAN_f1),"--{0:.4f}".format(RAN_Acc),"-- {0:.4f}".format(RAN_roc_auc)," --",RAN_train_time
    print "##############################################################################################"


###########################################
# PLOTTING
###########################################

if (argumentos[1]=='2'):
    print "\nROC Curve"
    fig = plt.figure(figsize=(15, 15))
    
    plt.plot(fpr_forest, tpr_forest, linewidth=2, label='Roc Curve de Random Forest Classifier (area= %0.4f)' % RAN_roc_auc)
    
    plt.plot(fpr_lr, tpr_lr, linewidth=2, label='Roc Curve de Logistic Regression (area= %0.4f)' % LOG_roc_auc)
    plt.plot(fpr_svm, tpr_svm, linewidth=2, label='Roc Curve de SVM (area= %0.4f)' % SVM_roc_auc)
    plt.plot(fpr_knn, tpr_knn, linewidth=2, label='Roc Curve de KNN(area = %0.4f)' % KNN_roc_auc)
    
    fig.tight_layout()
    plt.plot([0,1],[0,1],"k--")
    plt.axis([0,1,0,1])
    plt.xlabel("False Positive rate")
    plt.ylabel("True Positive rate")
    plt.legend()
    plt.show()
    plt.savefig('resultados/Roc_Curve_With_RandomForest_testado.png', bbox_inches='tight')

