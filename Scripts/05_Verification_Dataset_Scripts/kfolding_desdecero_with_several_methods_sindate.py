import numpy as np
from numpy import *
import pandas as pd
from time import time
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn import manifold
from sklearn.manifold import TSNE
from sklearn.externals import joblib
import sys

def syntax_error():
        print "SYNTAX ERROR: Introduce dos argumentos con los siguientes valores"
        print "Primer argumento:"
        print " 1 Quitar todos los campos DIST"
        print " 2 Dejar los campos DIST"
        print
        print "Segundo argumento:"
        print " 1 Recalcular TSNE"
        print " 2 Obtener calculo de la ultima operacion grabada"


argumentos=sys.argv
if len(argumentos)!=3:
        syntax_error()
        sys.exit()
else:
        if (argumentos[1]!='1' and argumentos[1]!='2') or (argumentos[2]!='1' and argumentos[2]!='2'):
                syntax_error()
                sys.exit()

##################################
# PREPARATIVOS
##################################

########
###Leemos el dataset
#input_file = "../datasets/csv_a_empezar_desde_cero_v2_sin_cols21y37_con52_y_49_46_y43_40_34_31_28_24_17_14_10_final_con_cabecera_quitamos_5_muestras.csv"
input_file = "../datasets/csv_a_empezar_desde_cero_v2_sin_cols21y37_con52_y_49_46_y43_40_34_31_28_24_17_14_10_final_con_cabecera_quitamos_5_muestras_develgroup_country_new_headers.csv"

df = pd.read_csv(input_file, header = 0, sep=';', dtype={"MD5":object,"FIRST_SEEN":object,"SIZE":int,"NUM_PACKERS":float64,"PACKERS_BIN":float64,"PACKERS_BIN_DIST":float64,"MALWARE_TYPE":object,"NUM_IMPORTS":float64,"IMPORTS_BIN":float64,"IMPORTS_BINARY_DIST":float64,"HAS_OVERLAYS":int,"SUSPICIOUS_DLLS":float64,"SUSPICIOUS_DLLS_DIST":float64,"ANTIDEBUG_BINARY":float64,"ANTIDEBUG_BINARY_DIST":float64,"NUM_LANG":float64,"LANG_BINARY":float64,"LANG_BINARY_DIST":float64,"API_BINARY":float64,"API_BINARY_DIST":float64,"RESOURCE_NUM":int,"SERVICES_BINARY":float64,"SERVICES_BINARY_DIST":float64,"all_files_binary":float64,"all_files_binary_DIST":float64,"all_opened_files_binary":float64,"all_opened_files_binary_DIST":float64,"all_written_files_binary":float64,"all_written_files_binary_DIST":float64,"all_deleted_files_binary":float64,"all_deleted_files_binary_DIST":float64,"all_read_files_binary":float64,"all_read_files_binary_DIST":float64,"UDP_Countries":float64,"UDP_Countries_DIST":float64,"TCP_countries":float64,"TCP_countries_DIST":float64,"DNS_countries":float64,"DNS_countries_DIST":float64,"SSDEEP":int,"IMPHASH":int,"APT":int,"NUM_APT":int})

########
###Separamos los campos que no nos interesan y campos objetivo
malwaretypes=df.MALWARE_TYPE
ssdeeptypes=df.SSDEEP
imphashtypes=df.IMPHASH
isapt=df.APT
numapt=df.NUM_APT
md5=df.MD5

########
###Quitamos las cabeceras de los campos objetivo
values=malwaretypes.values.astype(np.int64)
values2=isapt.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

########
###Quitamos los campos que no nos interesan
#del df['MALWARE_TYPE']
del df['APT']
del df['MD5']
#del df['FIRST_SEEN']
#del df['SSDEEP']
#del df['IMPHASH']
del df['NUM_APT']
del df['DEVEL_GROUP']
del df['DEVEL_COUNTRY']

########
###Convertimos el campo fecha a un valor numerico (segundos desde 1/1/1970)
import datetime
def convert_to_year(date_in_some_format):
        datetime_object = datetime.datetime.strptime(date_in_some_format, '%d/%m/%Y %H:%M')
        totalmins=(datetime_object-datetime.datetime(1970,1,1)).total_seconds()/60
        return int(totalmins)

#df['DATE'] = df['FIRST_SEEN'].apply(convert_to_year)
del df['FIRST_SEEN']


########
####Quitamos los campos DIST
del df['UNKNOWN1']
del df['UNKNOWN2']
del df['UNKNOWN3']
del df['UNKNOWN4']
del df['UNKNOWN5']
del df['UNKNOWN6']
del df['UNKNOWN7']
del df['UNKNOWN8']
del df['UNKNOWN9']
del df['UNKNOWN10']
del df['UNKNOWN11']
del df['UNKNOWN12']
del df['UNKNOWN13']
del df['UNKNOWN15']
del df['UNKNOWN16']


if argumentos[1]=='1':
	del df['PACKERS_BIN_DIST']
	del df['IMPORTS_BINARY_DIST']
	del df['ANTIDEBUG_BINARY_DIST']
	del df['LANG_BINARY_DIST']
	del df['API_BINARY_DIST']
	del df['SERVICES_BINARY_DIST']
	del df['all_files_binary_DIST']
	del df['all_opened_files_binary_DIST']
	del df['all_written_files_binary_DIST']
	del df['all_deleted_files_binary_DIST']
	del df['all_read_files_binary_DIST']
	del df['UDP_Countries_DIST']
	del df['TCP_countries_DIST']
	del df['DNS_countries_DIST']
	del df['SUSPICIOUS_DLLS_DIST']
	del df['PACKERS_BIN']
	del df['IMPORTS_BIN']
	del df['ANTIDEBUG_BINARY']
	del df['LANG_BINARY']
	del df['API_BINARY']
	del df['SERVICES_BINARY']
	del df['all_files_binary']
	del df['all_opened_files_binary']
	del df['all_written_files_binary']
	del df['all_deleted_files_binary']
	del df['all_read_files_binary']
	del df['UDP_Countries']
	del df['TCP_countries']
	del df['DNS_countries']
	del df['SUSPICIOUS_DLLS']

##################################
# RELLENAMOS VALORES VACIOS
##################################
#X=joblib.load("../tmp/dataset_mas_completo.joblib.pkl",  mmap_mode='r')
X=joblib.load("../tmp/dataset_mas_completo_sin_imphash_sin_ssdeeP_sin_date.joblib.pkl",  mmap_mode='r')

#from sklearn.impute import SimpleImputer
#imp = SimpleImputer(strategy="most_frequent")
#X=imp.fit_transform(df)

#joblib.dump(X, "../tmp/dataset_limpiado.joblib.pkl")
#exit()


##################################
# Standarization
##################################
from sklearn import preprocessing
#df = preprocessing.scale(df)
X = preprocessing.scale(X)

##################################
# Preparando Training y Testing sets
##################################
#
#Barajamos las muestras. Realmente lo que se barajan son los indices.
shuffle_index=np.random.permutation(17000)

#Nos quedamos con los valores, descartando las cabeceras
#df3=df.values
#df=df.values
df3=X
df=X

###########
#X_train son las 17000 primeras muestras. X_test son las 3547 ultimas muestras
#Y_train es un 0 o un 1 por cada una de esas 17000 muestras indicando si se trata de un APT o no
#Y_test es un 0 o un 1 por cada una de esas 3547 muestras indicando si se trata de un APT o no
X_train,X_test,Y_train,Y_test=df[:17000],df[17000:],isapt[:17000],isapt[17000:]

#############
#Calculamos un test set con el mismo numero de malware que de APTs
total=200
numAPT=0
numMAL=0
XequalSet=[]
YequalSet=pd.Series()
numTotal=1

for i in range(1,20529):
        if numAPT<total and isapt[i]==1:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numAPT+=1
                numTotal+=1

        if numMAL<total and isapt[i]==0:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numMAL+=1
                numTotal+=1

        if numAPT>=total and numMAL>=total:
                break

XequalSet = np.array(XequalSet)

#Al final en Xequalset y en YEqualset hay 400 muestras, 200 son APTs y 200 son malware generico

###########################################
# TARGET VECTORS
###########################################


#Pasamos de valores 0 o 1 a valores true or false:
Y_train_APT=(Y_train == 1)
Y_test_APT=(Y_test == 1)


print ("################################################")
print ("             RANDOM FOREST")
print ("################################################")


###########################################
# Random Forest Classifier
###########################################
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

#Creamos el clasificador. El random_state value no deberia afectar
forest_clf = RandomForestClassifier(random_state=42)

#Y lo entrenamos con el training Set
forest_clf.fit(X_train, Y_train_APT)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=forest_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(forest_clf, X_test, Y_test_APT, cv=3)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 7 foldings:"
print "%porcentaje de acierto....", cross_val_score(forest_clf, X_test, Y_test_APT, cv=7, scoring="accuracy")*100


###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


###########
# ROC AUC (Area under Curve) Score
###########
from sklearn.metrics import roc_auc_score
y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=3, method="predict_proba")

y_scores_forest=y_probabilities_forest[:,1]
print "\nROC AUC Score"
print roc_auc_score(Y_train_APT, y_scores_forest)


###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))






###########################################
# AHORA INTENTAMOS CON UN TEST SET QUE TENGA EL MISMO NUMERO DE APTs Y MALWARE
###########################################
#Pasamos de valores 0 o 1 a valores true or false:
Y_test_equal=(YequalSet == 1)


##Y luego lo calculamos con la funcion de sklearn predict:
y_test_equal_pred=cross_val_predict(forest_clf, XequalSet, Y_test_equal, cv=3)

##Calculamos el porcentaje de aciertos. Primero lo hacemos a mano...
YY=YequalSet.values
acierto=0
total=0
for i in range(0,400):
        total=total+1
        ej=XequalSet[i]
        prediction=forest_clf.predict([ej])

        if (prediction) and YY[i]==1:
                acierto=acierto + 1
        if (not prediction) and YY[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


print "%porcentaje de acierto....", cross_val_score(forest_clf, XequalSet, Y_test_equal, cv=7, scoring="accuracy")*100


###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_equal,y_test_equal_pred)

print "\nPrecision Score:"
print precision_score(Y_test_equal,y_test_equal_pred)
print "\nRecall Score:"
print recall_score(Y_test_equal,y_test_equal_pred)


###########
# ROC AUC Score
###########
from sklearn.metrics import roc_auc_score
y_scores_forest=y_probabilities_forest[:,1]

print "\nROC AUC Score"
print roc_auc_score(Y_train_APT, y_scores_forest)


###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_equal, y_test_equal_pred, target_names=["Malware","APT"]))




print ("################################################")
print ("             DECISSION TREE")
print ("################################################")


###########################################
# Decission Tree Classifier
###########################################
from sklearn import tree
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

#Creamos el clasificador. El random_state value no deberia afectar
tree_clf = tree.DecisionTreeClassifier()

#Y lo entrenamos con el training Set
fitted_tree_clf=tree_clf.fit(X_train, Y_train_APT)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=tree_clf.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(tree_clf, X_test, Y_test_APT, cv=7)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 7 foldings:"
print "%porcentaje de acierto....", cross_val_score(tree_clf, X_test, Y_test_APT, cv=7, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)



###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))


print ("################################################")
print ("            SVM")
print ("################################################")

###########################################
# SVM
###########################################
from sklearn import svm

#Creamos el clasificador. El random_state value no deberia afectar
svm_clf = svm.LinearSVC()

#Y lo entrenamos con el training Set
svm_clf.fit(X_train, Y_train_APT)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=svm_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(svm_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 7 foldings:"
print "%porcentaje de acierto....", cross_val_score(svm_clf, X_test, Y_test_APT, cv=7, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("################################################")
print ("            KNN")
print ("################################################")

###########################################
# KNN
###########################################
from sklearn import svm
from sklearn import neighbors, datasets

#Creamos el clasificador. El random_state value no deberia afectar
knn_clf = neighbors.KNeighborsClassifier()

#Y lo entrenamos con el training Set
knn_clf.fit(X_train, Y_train_APT)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=knn_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(knn_clf, X_test, Y_test_APT)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 7 foldings:"
print "%porcentaje de acierto....", cross_val_score(knn_clf, X_test, Y_test_APT, cv=7, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)





#########
# ROC Curve
#
# Esta grafica nos permite decidir cual de los clasificadores son mejores
###########
from sklearn.metrics import roc_curve

#Aqui Obtenemos probabilidades, a partir de los sets de training de cada clase
y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=3, method="predict_proba")

#Esto devuelve un array del tipo( Probabilidades de que si, probabilidades de que no):
#[[1.  0. ]
# [1.  0. ]
# ...
# [0.7 0.3]
# [0.6 0.4]
# [0.  1. ]]

print "\nROC Curve"
fig = plt.figure(figsize=(15, 15))

######RANDOM FOREST########
y_scores_forest=y_probabilities_forest[:,1]
fpr_forest, tpr_forest, threshold_forest=roc_curve(Y_train_APT,y_scores_forest)

plt.plot(fpr_forest, tpr_forest, linewidth=2, label=None)

######DECISSION TREE########

y_probabilities_decission=cross_val_predict(tree_clf, X_train, Y_train_APT, cv=7, method="predict_proba")
y_scores_decission=y_probabilities_decission[:,1]
fpr_decission, tpr_decission, threshold_decission=roc_curve(Y_train_APT,y_scores_decission)

plt.plot(fpr_decission, tpr_decission, linewidth=2, label=None)

######SVM########

y_probabilities_svm=cross_val_predict(svm_clf, X_train, Y_train_APT, cv=7)
print y_probabilities_svm
y_scores_svm=y_probabilities_svm[:,1]
fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_train_APT,y_scores_svm)

plt.plot(fpr_svm, tpr_svm, linewidth=2, label=None)

######KNN########

y_probabilities_knn=cross_val_predict(knn_clf, X_train, Y_train_APT, cv=7)
y_scores_knn=y_probabilities_knn[:,1]
fpr_knn, tpr_knn, threshold_knn=roc_curve(Y_train_APT,y_scores_knn)

plt.plot(fpr_knn, tpr_knn, linewidth=2, label=None)


plt.plot([0,1],[0,1],"k--")
plt.axis([0,1,0,1])
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")
plt.legend()
plt.show()
plt.savefig('resultados/Roc_Curve_With_RandomForest_desde_cero_sindate.png')

