import numpy as np
from numpy import *
import pandas as pd
from time import time
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn import manifold
from sklearn.manifold import TSNE
from sklearn.externals import joblib
import sys
import time
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

start = time.time()
##################################
# PREPARATIVOS
##################################

########
###Leemos el dataset
input_file = "../datasets/csv_a_empezar_desde_cero_v2_sin_cols21y37_con52_y_49_46_y43_40_34_31_28_24_17_14_10_final_con_cabecera_quitamos_5_muestras_develgroup_country_new_headers.csv"
input_file2 = "../datasets/newDatasetFinal5.csv"

df = pd.read_csv(input_file2, header = 0, sep=";")

total_muestras=df.shape[0]
print (total_muestras)

########
###Separamos los campos que no nos interesan y campos objetivo
isapt=df.APT
ssdeeptypes=df.SSDEEP
malwaretypes=df['MALWARE_TYPE']
imphashtypes=df.IMPHASH
numapt=df.NUM_APT
md5=df.MD5

#EXPLOTAMOS MALWARE_TYPE EN TIPOS:
#df['isTypeUnknown'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,-1), axis=1)
#df['isOtherType'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,0), axis=1)
#df['isTrojan'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,1), axis=1)
#df['isWorm'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,2), axis=1)
#df['isBackdoor'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,3), axis=1)
#df['isRootkit'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,4), axis=1)
#df['isSpyware'] = df.apply (lambda row: convert_malware_type_to_new_fields(row,5), axis=1)

########
###Quitamos las cabeceras de los campos objetivo
values=malwaretypes.values.astype(np.int64)
values2=isapt.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

########
###Quitamos los campos que no nos interesan
#del df['MALWARE_TYPE']
del df['APT']
del df['MD5']
del df['FIRST_SEEN']
del df['SSDEEP']
del df['IMPHASH']
del df['NUM_APT']
del df['DEVEL_GROUP']
del df['DEVEL_COUNTRY']

########
###Convertimos el campo fecha a un valor numerico (segundos desde 1/1/1970)
import datetime
def convert_to_year(date_in_some_format):
        datetime_object = datetime.datetime.strptime(date_in_some_format, '%d/%m/%Y %H:%M')
        totalmins=(datetime_object-datetime.datetime(1970,1,1)).total_seconds()/60
        return int(totalmins)


########
####Quitamos los campos DIST
del df['UNKNOWN1']
del df['UNKNOWN2']
del df['UNKNOWN3']
del df['UNKNOWN4']
del df['UNKNOWN5']
del df['UNKNOWN6']
del df['UNKNOWN7']
del df['UNKNOWN8']
del df['UNKNOWN9']
del df['UNKNOWN10']
del df['UNKNOWN11']
del df['UNKNOWN12']
del df['UNKNOWN13']
del df['UNKNOWN15']
del df['UNKNOWN16']


del df['PACKERS_BIN_DIST']
del df['IMPORTS_BINARY_DIST']
del df['ANTIDEBUG_BINARY_DIST']
del df['LANG_BINARY_DIST']
del df['API_BINARY_DIST']
del df['SERVICES_BINARY_DIST']
del df['all_files_binary_DIST']
del df['all_opened_files_binary_DIST']
del df['all_written_files_binary_DIST']
del df['all_deleted_files_binary_DIST']
del df['all_read_files_binary_DIST']
del df['UDP_Countries_DIST']
del df['TCP_countries_DIST']
del df['DNS_countries_DIST']
del df['SUSPICIOUS_DLLS_DIST']
del df['PACKERS_BIN']
del df['IMPORTS_BIN']
del df['ANTIDEBUG_BINARY']
del df['LANG_BINARY']
del df['API_BINARY']
del df['SERVICES_BINARY']
del df['all_files_binary']
del df['all_opened_files_binary']
del df['all_written_files_binary']
del df['all_deleted_files_binary']
del df['all_read_files_binary']
del df['UDP_Countries']
del df['TCP_countries']
del df['DNS_countries']
del df['SUSPICIOUS_DLLS']

df1=df[['ALL_FILES_C:','ALL_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft','ALL_FILES_C:/Program_Files/Common_Files/System/Ole_DB','ALL_FILES_C:/Program_Files/Windows_NT/Accessories','ANTIDEBUG_CheckRemoteDebuggerPresent','ANTIDEBUG_FindWindowExA','ANTIDEBUG_FindWindowExW','ANTIDEBUG_GetWindowThreadProcessId','ANTIDEBUG_%IsDebuggerPresent','ANTIDEBUG_OutputDebugStringA','ANTIDEBUG_Process32NextW','DELETED_FILES_C:','DELETED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','DELETED_FILES_C:/Documents_and_Settings/All_Users/Application_Data','DELETED_FILES_C:/Documents_and_Settings/All_Users/Start_Menu/Programs','DELETED_FILES_C:/Documents_and_Settings/<USER>/Desktop','DELETED_FILES_c:/windows/temp','DNS_CH','DNS_CZ','DNS_IL','DNS_NL','DNS_SY','IMPORTS_BIN_bind','IMPORTS_BIN_CallNextHookEx','IMPORTS_BIN_CharNextA','IMPORTS_BIN_CloseHandle','IMPORTS_BIN_CopyFile','IMPORTS_BIN_CreateDirectoryA','IMPORTS_BIN_CreateMutex','IMPORTS_BIN_CreateSymbolicLink','IMPORTS_BIN_DeleteCriticalSection','IMPORTS_BIN_DispatchMessageA','IMPORTS_BIN_EnterCriticalSection','IMPORTS_BIN_FindNextFile','IMPORTS_BIN_FindWindow','IMPORTS_BIN_FreeLibrary','IMPORTS_BIN_GetClientRect','IMPORTS_BIN_GetCurrentThreadId','IMPORTS_BIN_GetDC','IMPORTS_BIN_GetDeviceCaps','IMPORTS_BIN_GetDlgItem','IMPORTS_BIN_GetFileInformation','IMPORTS_BIN_GetFileTime','IMPORTS_BIN_GetFileType','IMPORTS_BIN_GetLastError','IMPORTS_BIN_GetLongPathName','IMPORTS_BIN_GetSystemDirectoryA','IMPORTS_BIN_GetTempPathA','IMPORTS_BIN_GetVersion','IMPORTS_BIN_GetWindowLongA','IMPORTS_BIN_GetWindowsDirectory','IMPORTS_BIN_GlobalAlloc','IMPORTS_BIN_GlobalFree','IMPORTS_BIN_GlobalUnlock','IMPORTS_BIN_HeapFree','IMPORTS_BIN_inet_addr','IMPORTS_BIN_InitializeCriticalSection','IMPORTS_BIN_IsDebuggerPresent','IMPORTS_BIN_LeaveCriticalSection','IMPORTS_BIN_LoadLibrary','IMPORTS_BIN_lstrcpynA','IMPORTS_BIN_MapViewOfFile','IMPORTS_BIN_OpenFile','IMPORTS_BIN_RegOpenKey','IMPORTS_BIN_RegQueryValueExA','IMPORTS_BIN_RegSetValueExA','IMPORTS_BIN_SelectObject','IMPORTS_BIN_SetFilePointer','IMPORTS_BIN_SetWindowLongA','IMPORTS_BIN_ShowWindow','IMPORTS_BIN_TlsGetValue','IMPORTS_BIN_wsprintfA','OPENED_FILES_C:','OPENED_FILES_C:/Documents_and_Settings/<USER>','OPENED_FILES_C:/Documents_and_Settings/<USER>/Start_Menu/Programs/Startup','OPENED_FILES_C:/WINDOWS/Registration','OPENED_FILES_C:/WINDOWS/system','OPENED_FILES_C:/WINDOWS/system32','OPENED_FILES_c:/windows/temp','OPENED_FILES_//./Global','PACKER_Armadillo','PACKER_NullSoft','PACKER_UPX','READ_FILES_C:','READ_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft/Internet_Explorer/Quick_Launch','SERVICES_AudioSrv','SERVICES_Ias','SERVICES_NetDDEdsdm','SERVICES_Ntmssvc','SERVICES_RASMAN','SERVICES_Win32','SERVICES_WmiApSrv','SUSP_API_CopyFileA','SUSP_API_CopyFileW','SUSP_API_CreateFileA','SUSP_API_CreateProcessAsUserA','SUSP_API_CreateProcessW','SUSP_API_CreateProcessWithLogonW','SUSP_API_CreateServiceW','SUSP_API_CreateThread','SUSP_API_CryptEncrypt','SUSP_API_DeleteFileA','SUSP_API_DisconnectNamedPipe','SUSP_API_FindFirstFileA','SUSP_API_FindFirstFileExW','SUSP_API_GetCommandLineW','SUSP_API_GetModuleFileNameA','SUSP_API_GetProcAddress','SUSP_API_GetStartupInfoA','SUSP_API_GetStartupInfoW','SUSP_API_GetTempPathW','SUSP_API_GetVersionExA','SUSP_API_HttpSendRequestExA','SUSP_API_HttpSendRequestExW','SUSP_API_InternetConnectA','SUSP_API_InternetOpenA','SUSP_API_InternetOpenUrlA','SUSP_API_InternetQueryOptionA','SUSP_API_LoadLibraryA','SUSP_API_LoadLibraryExA','SUSP_API_LoadLibraryW','SUSP_API_LockResource','SUSP_API_OpenFileMappingW','SUSP_API_OpenProcess','SUSP_API_RegCreateKeyExA','SUSP_API_RegCreateKeyW','SUSP_API_RegDeleteValueA','SUSP_API_RegEnumKeyA','SUSP_API_RegEnumKeyExA','SUSP_API_RegOpenKeyExA','SUSP_API_ShellExecuteExA','SUSP_API_SleepEx','SUSP_API_StartServiceA','SUSP_API_StartServiceCtrlDispatcherW','SUSP_API_StartServiceW','SUSP_API_VirtualFree','SUSP_API_WriteFile','SUSP_API_WriteProcessMemory','SUSP_DLLS_ADVAPI32.dll','SUSP_DLLS_comdlg32.dll','SUSP_DLLS_crypt32.dll','SUSP_DLLS_GDI32.DLL','SUSP_DLLS_HAL.dll','SUSP_DLLS_KERNEL32.dll','SUSP_DLLS_MFC42.DLL','SUSP_DLLS_MSVFW32.dll','SUSP_DLLS_ntoskrnl.exe','SUSP_DLLS_OLE32.DLL','SUSP_DLLS_OPENGL32.DLL','SUSP_DLLS_SECUR32.dll','SUSP_DLLS_wininet.dll','SUSP_DLLS_WSOCK32.DLL','TCP_AE','TCP_CH','TCP_CN','TCP_DE','TCP_KR','TCP_MD','TCP_NL','TCP_US','UDP_CL','UDP_GB','UDP_MD','UDP_MT','UDP_US','ALL_FILES_C:/WINDOWS/system32','ANTIDEBUG_TerminateProcess','ANTIDEBUG_UnhandledExceptionFilter','DNS_US','HAS_OVERLAYS','IMPORTS_BIN_CreateFile','IMPORTS_BIN_CreateProcessA','IMPORTS_BIN_DeleteFile','IMPORTS_BIN_DeleteObject','IMPORTS_BIN_ExitProcess','IMPORTS_BIN_FileSize','IMPORTS_BIN_FindFirstFile','IMPORTS_BIN_GetACP','IMPORTS_BIN_GetCPInfo','IMPORTS_BIN_GetCurrentProcess','IMPORTS_BIN_GetFileAttributes','IMPORTS_BIN_GetFileAttributesA','IMPORTS_BIN_GetFullPathName','IMPORTS_BIN_GetShortPathName','IMPORTS_BIN_GetStdHandle','IMPORTS_BIN_GetTempFileName','IMPORTS_BIN_GlobalLock','IMPORTS_BIN_HeapAlloc','IMPORTS_BIN_lstrlenA','IMPORTS_BIN_MoveFile','IMPORTS_BIN_MultiByteToWideChar','IMPORTS_BIN_ReadFile','IMPORTS_BIN_RegCloseKey','IMPORTS_BIN_RtlUnwind','IMPORTS_BIN_SetErrorMode','IMPORTS_BIN_SetFileAttributes','IMPORTS_BIN_SetFileTime','IMPORTS_BIN_WaitForSingleObject','IMPORTS_BIN_WideCharToMultiByte','MALWARE_TYPE','NUM_IMPORTS','NUM_LANG','NUM_PACKERS','OPENED_FILES_//.','OPENED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','OPENED_FILES_C:/WINDOWS','OPENED_FILES_//./PIPE','READ_FILES_C:/WINDOWS/Registration','READ_FILES_C:/WINDOWS/system32','RESOURCE_NUM','SUSP_API_CreateFileW','SUSP_API_FindNextFileA','SUSP_API_FindResourceA','SUSP_API_GetCommandLineA','SUSP_API_GetFileSize','SUSP_API_GetModuleHandleA','SUSP_API_GetTempFileNameA','SUSP_API_GetTickCount','SUSP_API_RegDeleteKeyA','SUSP_API_ShellExecuteA','SUSP_API_Sleep','SUSP_API_VirtualAlloc','SUSP_API_VirtualProtect','SUSP_DLLS_COMCTL32.DLL','SUSP_DLLS_Msvcrt.dll','SUSP_DLLS_OLEAUT32.DLL','SUSP_DLLS_Shell32.dll','SUSP_DLLS_SHLWAPI.dll','SUSP_DLLS_USER32.dll','SUSP_DLLS_version.dll']]

#num=230

#df=df1.iloc[0:20449,0:num]
df=df1

print df.shape

print("Dataframe obtained:")
end = time.time()
print(end - start)

##################################
# RELLENAMOS VALORES VACIOS
##################################


#X=joblib.load("../tmp/dataset_limpiado_imputado_standarizado_240_features.joblib.pkl",  mmap_mode='r')

from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy="most_frequent")
X=imp.fit_transform(df)

#joblib.dump(X, "../tmp/dataset_limpiado.joblib.pkl")
#exit()

print("Dataframe imputed:")
end = time.time()
print(end - start)

##################################
# Standarization
##################################
from sklearn import preprocessing
#df = preprocessing.scale(df)
X = preprocessing.scale(X)

print("Dataframe standardized:")
end = time.time()
print(end - start)
##################################
# Preparando Training y Testing sets
##################################
#
#Barajamos las muestras. Realmente lo que se barajan son los indices.
shuffle_index=np.random.permutation(17000)

#Nos quedamos con los valores, descartando las cabeceras
#df3=df.values
#df=df.values
df3=X
df=X

###########
#X_train son las 17000 primeras muestras. X_test son las 3547 ultimas muestras
#Y_train es un 0 o un 1 por cada una de esas 17000 muestras indicando si se trata de un APT o no
#Y_test es un 0 o un 1 por cada una de esas 3547 muestras indicando si se trata de un APT o no
X_train,X_test,Y_train,Y_test=df[:17000],df[17000:],isapt[:17000],isapt[17000:]

#############
#Calculamos un test set con el mismo numero de malware que de APTs
total=200
numAPT=0
numMAL=0
XequalSet=[]
YequalSet=pd.Series()
numTotal=1

for i in range(1,20529):
        if numAPT<total and isapt[i]==1:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numAPT+=1
                numTotal+=1

        if numMAL<total and isapt[i]==0:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numMAL+=1
                numTotal+=1

        if numAPT>=total and numMAL>=total:
                break

XequalSet = np.array(XequalSet)

#Al final en Xequalset y en YEqualset hay 400 muestras, 200 son APTs y 200 son malware generico

###########################################
# TARGET VECTORS
###########################################


#Pasamos de valores 0 o 1 a valores true or false:
Y_train_APT=(Y_train == 1)
Y_test_APT=(Y_test == 1)


print ("################################################")
print ("            KNN")
print ("################################################")

###########################################
# KNN
###########################################
from sklearn import neighbors, datasets
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

end = time.time()
print(end - start)
print("Starting KNN:") 
#Creamos el clasificador. El random_state value no deberia afectar
knn_clf = neighbors.KNeighborsClassifier(n_neighbors=2)

#Y lo entrenamos con el training Set
knn_clf.fit(X_train, Y_train_APT)

########
#knn_clf
########

print("Finishing KNN:") 
end = time.time()
print(end - start)
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
#acierto=0
#total=0
#for i in range(17000,20529):
#        total=total+1
#        ej=df3[i]
#        prediction=knn_clf.predict([ej])
#
#        #print i, prediction, isapt[i]
#        if (prediction) and isapt[i]==1:
#                acierto=acierto + 1
#        if (not prediction) and isapt[i]==0:
#                acierto=acierto + 1
#media=0.0
#media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


print("Y ahora hacemos la prediccion con la funcion de sklearn predict 10 foldings:")
y_test_pred=cross_val_predict(knn_clf, X_test, Y_test_APT)
array_scores=cross_val_score(knn_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100
print(array_scores.mean())

#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(knn_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)





print ("################################################")
print ("            DECISSION TREE ID3")
print ("################################################")

###########################################
# Decission Tree ID3
###########################################
from id3 import Id3Estimator
from id3 import export_graphviz

end = time.time()
print(end - start)
print("Starting ID3:") 
#Creamos el clasificador. El random_state value no deberia afectar
id3_clf = Id3Estimator()

#Y lo entrenamos con el training Set
id3_clf.fit(X_train, Y_train_APT)

########
#id3_clf
########

print("Finishing SVm:") 
end = time.time()
print(end - start)
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
#acierto=0
#total=0
#for i in range(17000,20529):
#        total=total+1
#        ej=df3[i]
#        prediction=id3_clf.predict([ej])
#
#        #print i, prediction, isapt[i]
#        if (prediction) and isapt[i]==1:
#                acierto=acierto + 1
#        if (not prediction) and isapt[i]==0:
#                acierto=acierto + 1
#media=0.0
#media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


print("Y ahora hacemos la prediccion con la funcion de sklearn predict 10 foldings:")
y_test_pred=cross_val_predict(id3_clf, X_test, Y_test_APT)
array_scores=cross_val_score(id3_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100
print(array_scores.mean())

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
#y_test_pred=cross_val_predict(id3_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(id3_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)



print ("################################################")
print ("            SVC")
print ("################################################")

###########################################
# SVC
###########################################
from sklearn import svm
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

print("Starting SVC:") 
end = time.time()
print(end - start)
#Creamos el clasificador. El random_state value no deberia afectar
svm_clf = svm.SVC(C=0.01, probability=True)

#Y lo entrenamos con el training Set
svm_clf.fit(X_train, Y_train_APT)

########
#svm_clf
########

print("Finishing SVm:") 
end = time.time()
print(end - start)

print("Y ahora hacemos la prediccion con la funcion de sklearn predict 10 foldings:")
y_test_pred=cross_val_predict(svm_clf, X_test, Y_test_APT)
array_scores=cross_val_score(svm_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100
print(array_scores.mean())
##Y ahora hacemos la prediccion con la funcion de sklearn predict:
#y_test_pred=cross_val_predict(svm_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

#print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
#print "%porcentaje de acierto....", cross_val_score(svm_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)




print ("################################################")
print ("            NAIVE BAYES")
print ("################################################")


print("Starting Naive Bayes:")
end = time.time()
print(end - start)

###############################################
# NAIVE BAYES
##############################################
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score


nb_clf =  GaussianNB()
fitted_nb_clf=nb_clf.fit(X_train, Y_train_APT)
nb_clf.fit(X_train, Y_train_APT)

##################
#fitted_nb_clf
##################

print("Finished Naive Bayes:")
end = time.time()
print(end - start)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=fitted_nb_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(fitted_nb_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_nb_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("################################################")
print ("            LOGISTIC REGRESSION")
print ("################################################")


print("Starting Logistic Regression:")
end = time.time()
print(end - start)

###############################################
# LOGISTIC REGRESSION
##############################################
from sklearn.linear_model import LogisticRegression

lr_clf = LogisticRegression()
fitted_lr_clf=lr_clf.fit(X_train, Y_train_APT)
lr_clf.fit(X_train, Y_train_APT)

###########
#fitted_lr_clf
###########

print("Finished Logistic Regression:")
end = time.time()
print(end - start)

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(fitted_lr_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_lr_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("################################################")
print ("             RANDOM FOREST")
print ("################################################")


###########################################
# Random Forest Classifier
###########################################
from sklearn.ensemble import RandomForestClassifier

print("Starting Random Forest:")
end = time.time()
print(end - start)

headers=list(df1)
headersArray=array(array(headers))

#Creamos el clasificador. El random_state value no deberia afectar
forest_clf = RandomForestClassifier(random_state=42,n_estimators=100)

#Y lo entrenamos con el training Set
fitted_forest_clf=forest_clf.fit(X_train, Y_train_APT)
forest_clf.fit(X_train, Y_train_APT)

###########
#fitted_forest_clf
###########

print("Scores:")
scores=np.column_stack((headersArray, map(lambda x: round(x, 4), forest_clf.feature_importances_)))

print("Finished Random Forest:")
end = time.time()
print(end - start)

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
#En y_test_pred se ha almacenado el array de predicciones
y_test_pred=cross_val_predict(forest_clf, X_test, Y_test_APT, cv=10)

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
array_scores=cross_val_score(forest_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100
print "%porcentaje de acierto....", cross_val_score(forest_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100


###########
# Confusion Matrix
###########
#from sklearn.metrics import confusion_matrix
#from sklearn.metrics import precision_score, recall_score

#print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

#print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
#print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


###########
# ROC AUC (Area under Curve) Score
###########
#from sklearn.metrics import roc_auc_score
#y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")
#
#y_scores_forest=y_probabilities_forest[:,1]
#print "\nROC AUC Score"
#print roc_auc_score(Y_train_APT, y_scores_forest)
#

###########
# Classification Report
###########
#from sklearn.metrics import classification_report
#print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))



print ("################################################")
print ("             DECISSION TREE")
print ("################################################")


###########################################
# Decission Tree Classifier
###########################################
from sklearn import tree
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

print("Starting Decission Tree:") 
end = time.time()
print(end - start)
#Creamos el clasificador. El random_state value no deberia afectar
tree_clf = tree.DecisionTreeClassifier()

#Y lo entrenamos con el training Set
fitted_tree_clf=tree_clf.fit(X_train, Y_train_APT)

#####################
#fitted_tree_clf
#####################

print("Finishing Decission Tree:") 
end = time.time()
print(end - start)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20529):
        total=total+1
        ej=df3[i]
        prediction=tree_clf.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(tree_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(tree_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)



###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))



##########
# ROC Curve
#
# Esta grafica nos permite decidir cual de los clasificadores son mejores
###########
from sklearn.metrics import roc_curve, auc

#Aqui Obtenemos probabilidades, a partir de los sets de training de cada clase
#y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")

#Esto devuelve un array del tipo( Probabilidades de que si, probabilidades de que no):
#[[1.  0. ]
# [1.  0. ]
# ...
# [0.7 0.3]
# [0.6 0.4]
# [0.  1. ]]

print "\nROC Curve"
fig = plt.figure(figsize=(15, 15))
#
#######RANDOM FOREST########
y_probabilities_forest=cross_val_predict(forest_clf, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_forest=y_probabilities_forest[:,1]
fpr_forest, tpr_forest, threshold_forest=roc_curve(Y_test_APT,y_scores_forest)
roc_auc = auc(fpr_forest, tpr_forest)
plt.plot(fpr_forest, tpr_forest, linewidth=2, label='Roc Curve de Random Forest Classifier (area= %0.4f)' % roc_auc)
#
#######DECISSION TREE########
y_probabilities_decission=cross_val_predict(tree_clf, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_decission=y_probabilities_decission[:,1]
fpr_decission, tpr_decission, threshold_decission=roc_curve(Y_test_APT,y_scores_decission)
roc_auc = auc(fpr_decission, tpr_decission)
plt.plot(fpr_decission, tpr_decission, linewidth=2, label='Roc Curve de Decission Tree Classifier (area= %0.4f)' % roc_auc)

#######SVC########
y_probabilities_svm=cross_val_predict(svm_clf, X_test, Y_test_APT, cv=5,method="predict_proba")
y_scores_svm=y_probabilities_svm[:,1]
fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_test_APT,y_scores_svm)
roc_auc = auc(fpr_svm, tpr_svm)
plt.plot(fpr_svm, tpr_svm, linewidth=2, label='Roc Curve de SVM (area= %0.4f)' % roc_auc)

#######KNN########
y_probabilities_knn=cross_val_predict(knn_clf, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_knn=y_probabilities_knn[:,1]
fpr_knn, tpr_knn, threshold_knn=roc_curve(Y_test_APT,y_scores_knn)
roc_auc = auc(fpr_knn, tpr_knn)
plt.plot(fpr_knn, tpr_knn, linewidth=2, label='Roc Curve de KNN(area = %0.4f)' % roc_auc)

######LOGISTIC REGRESSION########
y_probabilities_lr=cross_val_predict(lr_clf, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_lr=y_probabilities_lr[:,1]
fpr_lr, tpr_lr, threshold_lr = roc_curve(Y_test_APT, y_scores_lr)
roc_auc = auc(fpr_lr, tpr_lr)
plt.plot(fpr_lr, tpr_lr, linewidth=2, label='Roc Curve de Logistic Regression (area= %0.4f)' % roc_auc)

######PAINT IT!!!########
fig.tight_layout()
plt.plot([0,1],[0,1],"k--")
plt.axis([0,1,0,1])
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")
plt.legend()
plt.show()
plt.savefig('resultados/Roc_Curve_With_Original_data.png', bbox_inches='tight')




print("==================================")
print("COMENZAMOS A USAR LOS NUEVOS DATOS")
print("==================================")









start = time.time()

##################################
# PREPARATIVOS
##################################

df = pd.read_csv(input_file2, header = 0)
total_muestras=df.shape[0]
print (total_muestras)

##################################
# BARAJAMOS ORDEN
##################################
#Barajamos las muestras. Realmente lo que se barajan son los indices.

df = df.sample(frac=1).reset_index(drop=True)

########
###Separamos los campos que no nos interesan y campos objetivo
#malwaretypes=df.MALWARE_TYPE
isapt=df.isAPT
numapt=df.NUMAPT
md5=df.MD5

########
###Quitamos las cabeceras de los campos objetivo
#values=malwaretypes.values.astype(np.int64)
values2=isapt.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

########
###Quitamos los campos que no nos interesan
#del df['MALWARE_TYPE']
del df['isAPT']
del df['MD5']
del df['NUMAPT']

a = [9] * total_muestras

df.insert(2, "MALWARE_TYPE", a, True)
for i in range(0,total_muestras-1):
    if df['isTypeUnknown'][i] == 1:
                df['MALWARE_TYPE'][i]=-1
    if df['isOtherType'][i] == 1:
                df['MALWARE_TYPE'][i]=0
    if df['isTrojan'][i] == 1:
                df['MALWARE_TYPE'][i]=1
    #if df['isWorm'][i] == 1:
    #            df['MALWARE_TYPE'][i]=2
    if df['isBackdoor'][i] == 1:
                df['MALWARE_TYPE'][i]=3
    if df['isRootkit'][i] == 1:
                df['MALWARE_TYPE'][i]=4
    if df['isSpyware'][i] == 1:
                df['MALWARE_TYPE'][i]=5


#df1=df[['ALL_FILES_C:','ALL_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft','ALL_FILES_C:/Program_Files/Common_Files/System/Ole_DB','ALL_FILES_C:/Program_Files/Windows_NT/Accessories','ANTIDEBUG_CheckRemoteDebuggerPresent','ANTIDEBUG_FindWindowExA','ANTIDEBUG_FindWindowExW','ANTIDEBUG_GetWindowThreadProcessId','ANTIDEBUG_%IsDebuggerPresent','ANTIDEBUG_OutputDebugStringA','ANTIDEBUG_Process32NextW','DELETED_FILES_C:','DELETED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','DELETED_FILES_C:/Documents_and_Settings/All_Users/Application_Data','DELETED_FILES_C:/Documents_and_Settings/All_Users/Start_Menu/Programs','DELETED_FILES_C:/Documents_and_Settings/<USER>/Desktop','DELETED_FILES_c:/windows/temp','DNS_CH','DNS_CZ','DNS_IL','DNS_NL','DNS_SY','IMPORTS_BIN_bind','IMPORTS_BIN_CallNextHookEx','IMPORTS_BIN_CharNextA','IMPORTS_BIN_CloseHandle','IMPORTS_BIN_CopyFile','IMPORTS_BIN_CreateDirectoryA','IMPORTS_BIN_CreateMutex','IMPORTS_BIN_CreateSymbolicLink','IMPORTS_BIN_DeleteCriticalSection','IMPORTS_BIN_DispatchMessageA','IMPORTS_BIN_EnterCriticalSection','IMPORTS_BIN_FindNextFile','IMPORTS_BIN_FindWindow','IMPORTS_BIN_FreeLibrary','IMPORTS_BIN_GetClientRect','IMPORTS_BIN_GetCurrentThreadId','IMPORTS_BIN_GetDC','IMPORTS_BIN_GetDeviceCaps','IMPORTS_BIN_GetDlgItem','IMPORTS_BIN_GetFileInformation','IMPORTS_BIN_GetFileTime','IMPORTS_BIN_GetFileType','IMPORTS_BIN_GetLastError','IMPORTS_BIN_GetLongPathName','IMPORTS_BIN_GetSystemDirectoryA','IMPORTS_BIN_GetTempPathA','IMPORTS_BIN_GetVersion','IMPORTS_BIN_GetWindowLongA','IMPORTS_BIN_GetWindowsDirectory','IMPORTS_BIN_GlobalAlloc','IMPORTS_BIN_GlobalFree','IMPORTS_BIN_GlobalUnlock','IMPORTS_BIN_HeapFree','IMPORTS_BIN_inet_addr','IMPORTS_BIN_InitializeCriticalSection','IMPORTS_BIN_IsDebuggerPresent','IMPORTS_BIN_LeaveCriticalSection','IMPORTS_BIN_LoadLibrary','IMPORTS_BIN_lstrcpynA','IMPORTS_BIN_MapViewOfFile','IMPORTS_BIN_OpenFile','IMPORTS_BIN_RegOpenKey','IMPORTS_BIN_RegQueryValueExA','IMPORTS_BIN_RegSetValueExA','IMPORTS_BIN_SelectObject','IMPORTS_BIN_SetFilePointer','IMPORTS_BIN_SetWindowLongA','IMPORTS_BIN_ShowWindow','IMPORTS_BIN_TlsGetValue','IMPORTS_BIN_wsprintfA','OPENED_FILES_C:','OPENED_FILES_C:/Documents_and_Settings/<USER>','OPENED_FILES_C:/Documents_and_Settings/<USER>/Start_Menu/Programs/Startup','OPENED_FILES_C:/WINDOWS/Registration','OPENED_FILES_C:/WINDOWS/system','OPENED_FILES_C:/WINDOWS/system32','OPENED_FILES_c:/windows/temp','OPENED_FILES_//./Global','PACKER_Armadillo','PACKER_NullSoft','PACKER_UPX','READ_FILES_C:','READ_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft/Internet_Explorer/Quick_Launch','SERVICES_AudioSrv','SERVICES_Ias','SERVICES_NetDDEdsdm','SERVICES_Ntmssvc','SERVICES_RASMAN','SERVICES_Win32','SERVICES_WmiApSrv','SUSP_API_CopyFileA','SUSP_API_CopyFileW','SUSP_API_CreateFileA','SUSP_API_CreateProcessAsUserA','SUSP_API_CreateProcessW','SUSP_API_CreateProcessWithLogonW','SUSP_API_CreateServiceW','SUSP_API_CreateThread','SUSP_API_CryptEncrypt','SUSP_API_DeleteFileA','SUSP_API_DisconnectNamedPipe','SUSP_API_FindFirstFileA','SUSP_API_FindFirstFileExW','SUSP_API_GetCommandLineW','SUSP_API_GetModuleFileNameA','SUSP_API_GetProcAddress','SUSP_API_GetStartupInfoA','SUSP_API_GetStartupInfoW','SUSP_API_GetTempPathW','SUSP_API_GetVersionExA','SUSP_API_HttpSendRequestExA','SUSP_API_HttpSendRequestExW','SUSP_API_InternetConnectA','SUSP_API_InternetOpenA','SUSP_API_InternetOpenUrlA','SUSP_API_InternetQueryOptionA','SUSP_API_LoadLibraryA','SUSP_API_LoadLibraryExA','SUSP_API_LoadLibraryW','SUSP_API_LockResource','SUSP_API_OpenFileMappingW','SUSP_API_OpenProcess','SUSP_API_RegCreateKeyExA','SUSP_API_RegCreateKeyW','SUSP_API_RegDeleteValueA','SUSP_API_RegEnumKeyA','SUSP_API_RegEnumKeyExA','SUSP_API_RegOpenKeyExA','SUSP_API_ShellExecuteExA','SUSP_API_SleepEx','SUSP_API_StartServiceA','SUSP_API_StartServiceCtrlDispatcherW','SUSP_API_StartServiceW','SUSP_API_VirtualFree','SUSP_API_WriteFile','SUSP_API_WriteProcessMemory','SUSP_DLLS_ADVAPI32.dll','SUSP_DLLS_comdlg32.dll','SUSP_DLLS_crypt32.dll','SUSP_DLLS_GDI32.DLL','SUSP_DLLS_HAL.dll','SUSP_DLLS_KERNEL32.dll','SUSP_DLLS_MFC42.DLL','SUSP_DLLS_MSVFW32.dll','SUSP_DLLS_ntoskrnl.exe','SUSP_DLLS_OLE32.DLL','SUSP_DLLS_OPENGL32.DLL','SUSP_DLLS_SECUR32.dll','SUSP_DLLS_wininet.dll','SUSP_DLLS_WSOCK32.DLL','TCP_AE','TCP_CH','TCP_CN','TCP_DE','TCP_KR','TCP_MD','TCP_NL','TCP_US','UDP_CL','UDP_GB','UDP_MD','UDP_MT','UDP_US','ALL_FILES_C:/WINDOWS/system32','ANTIDEBUG_TerminateProcess','ANTIDEBUG_UnhandledExceptionFilter','DNS_US','HAS_OVERLAYS','IMPORTS_BIN_CreateFile','IMPORTS_BIN_CreateProcessA','IMPORTS_BIN_DeleteFile','IMPORTS_BIN_DeleteObject','IMPORTS_BIN_ExitProcess','IMPORTS_BIN_FileSize','IMPORTS_BIN_FindFirstFile','IMPORTS_BIN_GetACP','IMPORTS_BIN_GetCPInfo','IMPORTS_BIN_GetCurrentProcess','IMPORTS_BIN_GetFileAttributes','IMPORTS_BIN_GetFileAttributesA','IMPORTS_BIN_GetFullPathName','IMPORTS_BIN_GetShortPathName','IMPORTS_BIN_GetStdHandle','IMPORTS_BIN_GetTempFileName','IMPORTS_BIN_GlobalLock','IMPORTS_BIN_HeapAlloc','IMPORTS_BIN_lstrlenA','IMPORTS_BIN_MoveFile','IMPORTS_BIN_MultiByteToWideChar','IMPORTS_BIN_ReadFile','IMPORTS_BIN_RegCloseKey','IMPORTS_BIN_RtlUnwind','IMPORTS_BIN_SetErrorMode','IMPORTS_BIN_SetFileAttributes','IMPORTS_BIN_SetFileTime','IMPORTS_BIN_WaitForSingleObject','IMPORTS_BIN_WideCharToMultiByte','NUM_IMPORTS','NUM_LANG','NUM_PACKERS','OPENED_FILES_//.','OPENED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','OPENED_FILES_C:/WINDOWS','OPENED_FILES_//./PIPE','READ_FILES_C:/WINDOWS/Registration','READ_FILES_C:/WINDOWS/system32','RESOURCE_NUM','SUSP_API_CreateFileW','SUSP_API_FindNextFileA','SUSP_API_FindResourceA','SUSP_API_GetCommandLineA','SUSP_API_GetFileSize','SUSP_API_GetModuleHandleA','SUSP_API_GetTempFileNameA','SUSP_API_GetTickCount','SUSP_API_RegDeleteKeyA','SUSP_API_ShellExecuteA','SUSP_API_Sleep','SUSP_API_VirtualAlloc','SUSP_API_VirtualProtect','SUSP_DLLS_COMCTL32.DLL','SUSP_DLLS_Msvcrt.dll','SUSP_DLLS_OLEAUT32.DLL','SUSP_DLLS_Shell32.dll','SUSP_DLLS_SHLWAPI.dll','SUSP_DLLS_USER32.dll','SUSP_DLLS_version.dll','isTypeUnknown','isOtherType','isTrojan','isBackdoor','isRootkit','isSpyware']]

#df=df1

df_con_malware_type=df[['ALL_FILES_C:','ALL_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft','ALL_FILES_C:/Program_Files/Common_Files/System/Ole_DB','ALL_FILES_C:/Program_Files/Windows_NT/Accessories','ANTIDEBUG_CheckRemoteDebuggerPresent','ANTIDEBUG_FindWindowExA','ANTIDEBUG_FindWindowExW','ANTIDEBUG_GetWindowThreadProcessId','ANTIDEBUG_%IsDebuggerPresent','ANTIDEBUG_OutputDebugStringA','ANTIDEBUG_Process32NextW','DELETED_FILES_C:','DELETED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','DELETED_FILES_C:/Documents_and_Settings/All_Users/Application_Data','DELETED_FILES_C:/Documents_and_Settings/All_Users/Start_Menu/Programs','DELETED_FILES_C:/Documents_and_Settings/<USER>/Desktop','DELETED_FILES_c:/windows/temp','DNS_CH','DNS_CZ','DNS_IL','DNS_NL','DNS_SY','IMPORTS_BIN_bind','IMPORTS_BIN_CallNextHookEx','IMPORTS_BIN_CharNextA','IMPORTS_BIN_CloseHandle','IMPORTS_BIN_CopyFile','IMPORTS_BIN_CreateDirectoryA','IMPORTS_BIN_CreateMutex','IMPORTS_BIN_CreateSymbolicLink','IMPORTS_BIN_DeleteCriticalSection','IMPORTS_BIN_DispatchMessageA','IMPORTS_BIN_EnterCriticalSection','IMPORTS_BIN_FindNextFile','IMPORTS_BIN_FindWindow','IMPORTS_BIN_FreeLibrary','IMPORTS_BIN_GetClientRect','IMPORTS_BIN_GetCurrentThreadId','IMPORTS_BIN_GetDC','IMPORTS_BIN_GetDeviceCaps','IMPORTS_BIN_GetDlgItem','IMPORTS_BIN_GetFileInformation','IMPORTS_BIN_GetFileTime','IMPORTS_BIN_GetFileType','IMPORTS_BIN_GetLastError','IMPORTS_BIN_GetLongPathName','IMPORTS_BIN_GetSystemDirectoryA','IMPORTS_BIN_GetTempPathA','IMPORTS_BIN_GetVersion','IMPORTS_BIN_GetWindowLongA','IMPORTS_BIN_GetWindowsDirectory','IMPORTS_BIN_GlobalAlloc','IMPORTS_BIN_GlobalFree','IMPORTS_BIN_GlobalUnlock','IMPORTS_BIN_HeapFree','IMPORTS_BIN_inet_addr','IMPORTS_BIN_InitializeCriticalSection','IMPORTS_BIN_IsDebuggerPresent','IMPORTS_BIN_LeaveCriticalSection','IMPORTS_BIN_LoadLibrary','IMPORTS_BIN_lstrcpynA','IMPORTS_BIN_MapViewOfFile','IMPORTS_BIN_OpenFile','IMPORTS_BIN_RegOpenKey','IMPORTS_BIN_RegQueryValueExA','IMPORTS_BIN_RegSetValueExA','IMPORTS_BIN_SelectObject','IMPORTS_BIN_SetFilePointer','IMPORTS_BIN_SetWindowLongA','IMPORTS_BIN_ShowWindow','IMPORTS_BIN_TlsGetValue','IMPORTS_BIN_wsprintfA','OPENED_FILES_C:','OPENED_FILES_C:/Documents_and_Settings/<USER>','OPENED_FILES_C:/Documents_and_Settings/<USER>/Start_Menu/Programs/Startup','OPENED_FILES_C:/WINDOWS/Registration','OPENED_FILES_C:/WINDOWS/system','OPENED_FILES_C:/WINDOWS/system32','OPENED_FILES_c:/windows/temp','OPENED_FILES_//./Global','PACKER_Armadillo','PACKER_NullSoft','PACKER_UPX','READ_FILES_C:','READ_FILES_C:/Documents_and_Settings/<USER>/Application_Data/Microsoft/Internet_Explorer/Quick_Launch','SERVICES_AudioSrv','SERVICES_Ias','SERVICES_NetDDEdsdm','SERVICES_Ntmssvc','SERVICES_RASMAN','SERVICES_Win32','SERVICES_WmiApSrv','SUSP_API_CopyFileA','SUSP_API_CopyFileW','SUSP_API_CreateFileA','SUSP_API_CreateProcessAsUserA','SUSP_API_CreateProcessW','SUSP_API_CreateProcessWithLogonW','SUSP_API_CreateServiceW','SUSP_API_CreateThread','SUSP_API_CryptEncrypt','SUSP_API_DeleteFileA','SUSP_API_DisconnectNamedPipe','SUSP_API_FindFirstFileA','SUSP_API_FindFirstFileExW','SUSP_API_GetCommandLineW','SUSP_API_GetModuleFileNameA','SUSP_API_GetProcAddress','SUSP_API_GetStartupInfoA','SUSP_API_GetStartupInfoW','SUSP_API_GetTempPathW','SUSP_API_GetVersionExA','SUSP_API_HttpSendRequestExA','SUSP_API_HttpSendRequestExW','SUSP_API_InternetConnectA','SUSP_API_InternetOpenA','SUSP_API_InternetOpenUrlA','SUSP_API_InternetQueryOptionA','SUSP_API_LoadLibraryA','SUSP_API_LoadLibraryExA','SUSP_API_LoadLibraryW','SUSP_API_LockResource','SUSP_API_OpenFileMappingW','SUSP_API_OpenProcess','SUSP_API_RegCreateKeyExA','SUSP_API_RegCreateKeyW','SUSP_API_RegDeleteValueA','SUSP_API_RegEnumKeyA','SUSP_API_RegEnumKeyExA','SUSP_API_RegOpenKeyExA','SUSP_API_ShellExecuteExA','SUSP_API_SleepEx','SUSP_API_StartServiceA','SUSP_API_StartServiceCtrlDispatcherW','SUSP_API_StartServiceW','SUSP_API_VirtualFree','SUSP_API_WriteFile','SUSP_API_WriteProcessMemory','SUSP_DLLS_ADVAPI32.dll','SUSP_DLLS_comdlg32.dll','SUSP_DLLS_crypt32.dll','SUSP_DLLS_GDI32.DLL','SUSP_DLLS_HAL.dll','SUSP_DLLS_KERNEL32.dll','SUSP_DLLS_MFC42.DLL','SUSP_DLLS_MSVFW32.dll','SUSP_DLLS_ntoskrnl.exe','SUSP_DLLS_OLE32.DLL','SUSP_DLLS_OPENGL32.DLL','SUSP_DLLS_SECUR32.dll','SUSP_DLLS_wininet.dll','SUSP_DLLS_WSOCK32.DLL','TCP_AE','TCP_CH','TCP_CN','TCP_DE','TCP_KR','TCP_MD','TCP_NL','TCP_US','UDP_CL','UDP_GB','UDP_MD','UDP_MT','UDP_US','ALL_FILES_C:/WINDOWS/system32','ANTIDEBUG_TerminateProcess','ANTIDEBUG_UnhandledExceptionFilter','DNS_US','HAS_OVERLAYS','IMPORTS_BIN_CreateFile','IMPORTS_BIN_CreateProcessA','IMPORTS_BIN_DeleteFile','IMPORTS_BIN_DeleteObject','IMPORTS_BIN_ExitProcess','IMPORTS_BIN_FileSize','IMPORTS_BIN_FindFirstFile','IMPORTS_BIN_GetACP','IMPORTS_BIN_GetCPInfo','IMPORTS_BIN_GetCurrentProcess','IMPORTS_BIN_GetFileAttributes','IMPORTS_BIN_GetFileAttributesA','IMPORTS_BIN_GetFullPathName','IMPORTS_BIN_GetShortPathName','IMPORTS_BIN_GetStdHandle','IMPORTS_BIN_GetTempFileName','IMPORTS_BIN_GlobalLock','IMPORTS_BIN_HeapAlloc','IMPORTS_BIN_lstrlenA','IMPORTS_BIN_MoveFile','IMPORTS_BIN_MultiByteToWideChar','IMPORTS_BIN_ReadFile','IMPORTS_BIN_RegCloseKey','IMPORTS_BIN_RtlUnwind','IMPORTS_BIN_SetErrorMode','IMPORTS_BIN_SetFileAttributes','IMPORTS_BIN_SetFileTime','IMPORTS_BIN_WaitForSingleObject','IMPORTS_BIN_WideCharToMultiByte','NUM_IMPORTS','NUM_LANG','NUM_PACKERS','OPENED_FILES_//.','OPENED_FILES_C:/DOCUME~1/<USER>~1/LOCALS~1/Temp','OPENED_FILES_C:/WINDOWS','OPENED_FILES_//./PIPE','READ_FILES_C:/WINDOWS/Registration','READ_FILES_C:/WINDOWS/system32','RESOURCE_NUM','SUSP_API_CreateFileW','SUSP_API_FindNextFileA','SUSP_API_FindResourceA','SUSP_API_GetCommandLineA','SUSP_API_GetFileSize','SUSP_API_GetModuleHandleA','SUSP_API_GetTempFileNameA','SUSP_API_GetTickCount','SUSP_API_RegDeleteKeyA','SUSP_API_ShellExecuteA','SUSP_API_Sleep','SUSP_API_VirtualAlloc','SUSP_API_VirtualProtect','SUSP_DLLS_COMCTL32.DLL','SUSP_DLLS_Msvcrt.dll','SUSP_DLLS_OLEAUT32.DLL','SUSP_DLLS_Shell32.dll','SUSP_DLLS_SHLWAPI.dll','SUSP_DLLS_USER32.dll','SUSP_DLLS_version.dll','MALWARE_TYPE']]


df=df_con_malware_type
print df.shape

print("Dataframe obtained:")
end = time.time()
print(end - start)

##################################
# RELLENAMOS VALORES VACIOS
##################################

#from sklearn.impute import SimpleImputer
#imp = SimpleImputer(strategy="most_frequent")
#X=imp.fit_transform(df)

#print("Dataframe imputed:")
#end = time.time()
#print(end - start)

##################################
# Standarization
##################################
from sklearn import preprocessing
X = preprocessing.scale(df)

print("Dataframe standardized:")
end = time.time()
print(end - start)

##################################
# Preparando Training y Testing sets
##################################
#
total_muestras=4875
total_train_set=3600
total_test_set=total_muestras - total_train_set


#Nos quedamos con los valores, descartando las cabeceras
#df3=df.values
#df=df.values
df3=X
df=X


###########
#X_train son las 3600 primeras muestras. X_test son las 1275 ultimas muestras
#Y_train es un 0 o un 1 por cada una de esas 3600 muestras indicando si se trata de un APT o no
#Y_test es un 0 o un 1 por cada una de esas 1275 muestras indicando si se trata de un APT o no
X_train,X_test,Y_train,Y_test=df[:total_train_set],df[total_train_set+1:],isapt[:total_train_set],isapt[total_train_set+1:]

X_total=df
Y_total_APT=isapt

#############
#Calculamos un test set con el mismo numero de malware que de APTs
total=200
numAPT=0
numMAL=0
XequalSet=[]
YequalSet=pd.Series()
numTotal=1

for i in range(1,total_muestras):
        if numAPT<total and isapt[i]==1:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numAPT+=1
                numTotal+=1

        if numMAL<total and isapt[i]==0:
                a=np.array(df[i])
                XequalSet.append(a)
                YequalSet = YequalSet.set_value(numTotal, isapt[i])
                numMAL+=1
                numTotal+=1

        if numAPT>=total and numMAL>=total:
                break

XequalSet = np.array(XequalSet)

#Al final en Xequalset y en YEqualset hay 400 muestras, 200 son APTs y 200 son malware generico

###########################################
# TARGET VECTORS
###########################################

#Pasamos de valores 0 o 1 a valores true or false:
Y_train_APT=(Y_train == 1)
Y_test_APT=(Y_test == 1)


print ("################################################")
print ("            KNN")
print ("################################################")


###########################################
# KNN
###########################################
print("")
#Creamos el clasificador. El random_state value no deberia afectar
knn_clf_owndata = neighbors.KNeighborsClassifier(n_neighbors=2)

#Y lo entrenamos con el training Set
knn_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
##Y ahora hacemos la prediccion con la funcion de sklearn predict:
print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(knn_clf, X_test, Y_test_APT)

#En y_test_pred se ha almacenado el array de predicciones
print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(knn_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(knn_clf_owndata, X_test, Y_test_APT)

#En y_test_pred se ha almacenado el array de predicciones
print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(knn_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


########################################### ########################################### ###########################################
#                                                    Decission Tree Classifier
########################################### ########################################### ###########################################

print ("################################################")
print ("             DECISSION TREE")
print ("################################################")

print("")
#Creamos el clasificador. El random_state value no deberia afectar
tree_clf_owndata = tree.DecisionTreeClassifier()

#Y lo entrenamos con el training Set
tree_clf_owndata.fit(X_train, Y_train_APT)
fitted_tree_clf_owndata=tree_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=tree_clf.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(tree_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(tree_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)





print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")

print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=tree_clf_owndata.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(tree_clf_owndata, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(tree_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


###########
# Classification Report
###########
#from sklearn.metrics import classification_report
#print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))





###############################################################################################################################
#                                                Decission Tree ID3
###############################################################################################################################

print ("################################################")
print ("            DECISSION TREE ID3")
print ("################################################")
print("")
#Creamos el clasificador. El random_state value no deberia afectar
id3_clf_owndata = Id3Estimator()

#Y lo entrenamos con el training Set
id3_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=id3_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(id3_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(id3_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=id3_clf_owndata.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(id3_clf_owndata, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(id3_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


####################################################################################################################################
#                                          SVC 
####################################################################################################################################
print ("################################################")
print ("             SVC")
print ("################################################")

print("")
#Creamos el clasificador. El random_state value no deberia afectar
svm_clf_owndata = svm.SVC(C=0.5, probability=True)

#Y lo entrenamos con el training Set
svm_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=svm_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(svm_clf, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(svm_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)


print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=svm_clf_owndata.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(svm_clf_owndata, X_test, Y_test_APT)


#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(svm_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)





############################################### ############################################### ###############################################
#                                                              NAIVE BAYES
############################################### ############################################### ###############################################
print ("################################################")
print ("            NAIVE BAYES")
print ("################################################")


print("")

nb_clf_owndata =  GaussianNB()
nb_clf_owndata.fit(X_train, Y_train_APT)
fitted_nb_clf_owndata=nb_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=fitted_nb_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(fitted_nb_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_nb_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)




print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=fitted_nb_clf_owndata.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

##Y ahora hacemos la prediccion con la funcion de sklearn predict:
y_test_pred=cross_val_predict(fitted_nb_clf_owndata, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_nb_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)

print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)



############################################## ############################################## ###############################################
#                                                           LOGISTIC REGRESSION
############################################## ############################################## ##############################################
print ("################################################")
print ("            LOGISTIC REGRESSION")
print ("################################################")


print("")

lr_clf_owndata = LogisticRegression()
lr_clf_owndata.fit(X_train, Y_train_APT)
fitted_lr_clf_owndata=lr_clf_owndata.fit(X_train, Y_train_APT)

print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=fitted_lr_clf.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

print("Y ahora hacemos la prediccion con la funcion de sklearn predict")
y_test_pred=cross_val_predict(fitted_lr_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones
print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_lr_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)


print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)

print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")
print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=fitted_lr_clf_owndata.predict([ej])

        #print i, prediction, isapt[i]
        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

print("Y ahora hacemos la prediccion con la funcion de sklearn predict")
y_test_pred=cross_val_predict(fitted_lr_clf_owndata, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones
print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(fitted_lr_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)


print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)

########################################### ########################################### ###########################################
# Random Forest Classifier
########################################### ########################################### ###########################################
print ("################################################")
print ("             RANDOM FOREST")
print ("################################################")


print("")

headers=list(df1)
headersArray=array(array(headers))

#Creamos el clasificador. El random_state value no deberia afectar
forest_clf_owndata = RandomForestClassifier(random_state=42,n_estimators=100)

#Y lo entrenamos con el training Set
forest_clf_owndata.fit(X_train, Y_train_APT)

#print("Scores:")
#scores=np.column_stack((headersArray, map(lambda x: round(x, 4), forest_clf.feature_importances_)))
#print pd.DataFrame(scores).sort_values(1,axis = 0)
#print sorted(zip(map(lambda x: round(x, 4), forest_clf.feature_importances_), headersArray), reverse=True)

############################################
# Forest Regression
###########################################
#print "Features sorted by their score:"
#from sklearn.model_selection import ShuffleSplit
#from sklearn.ensemble import RandomForestRegressor
#from sklearn.metrics import r2_score
#from collections import defaultdict
#
#print "Features sorted by their score:"
#X = X_train
#Y = Y_train
#names=headersArray
#
#print "Features sorted by their score:"
#rf = RandomForestRegressor()
#scores = defaultdict(list)
#
#print "Features sorted by their score:"
##crossvalidate the scores on a number of different random splits of the data
#rs=ShuffleSplit(n_splits=100, test_size= .3)
#for train_idx, test_idx in rs.split(X):
#    X_train, X_test = X[train_idx], X[test_idx]
#    Y_train, Y_test = Y[train_idx], Y[test_idx]
#    r = rf.fit(X_train, Y_train)
#    acc = r2_score(Y_test, rf.predict(X_test))
#    for i in range(X.shape[1]):
#        X_t = X_test.copy()
#        np.random.shuffle(X_t[:, i])
#        shuff_acc = r2_score(Y_test, rf.predict(X_t))
#        scores[names[i]].append((acc-shuff_acc)/acc)
#print "Features sorted by their score:"
#print sorted([(round(np.mean(score), 4), feat) for
#              feat, score in scores.items()], reverse=True)
#
print ("PREDICT_WITH_ORIGINAL_CLASSIFIER")
print ("================================")
print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=forest_clf.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(forest_clf, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(forest_clf, X_test, Y_test_APT, cv=10, scoring="accuracy")*100

#
############
## Confusion Matrix
############

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)

print ("PREDICT_WITH_NEW_SHORT_CLASSIFIER")
print ("================================")
print("Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set")
acierto=0
total=0
for i in range(total_train_set,total_muestras):
        total=total+1
        ej=df3[i]
        prediction=forest_clf_owndata.predict([ej])

        if (prediction) and isapt[i]==1:
                acierto=acierto + 1
        if (not prediction) and isapt[i]==0:
                acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"

print("Y ahora hacemos la prediccion con la funcion de sklearn predict:")
y_test_pred=cross_val_predict(forest_clf_owndata, X_test, Y_test_APT, cv=10)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 10 foldings:"
print "%porcentaje de acierto....", cross_val_score(forest_clf_owndata, X_test, Y_test_APT, cv=10, scoring="accuracy")*100


############
## Confusion Matrix
############

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred)
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred)

###########
# ROC AUC (Area under Curve) Score
###########
#from sklearn.metrics import roc_auc_score
#y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")
#
#y_scores_forest=y_probabilities_forest[:,1]
#print "\nROC AUC Score"
#print roc_auc_score(Y_train_APT, y_scores_forest)


###########
# Classification Report
###########
#from sklearn.metrics import classification_report
#print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))




###########################################
# AHORA INTENTAMOS CON UN TEST SET QUE TENGA EL MISMO NUMERO DE APTs Y MALWARE
###########################################
#print("AHORA INTENTAMOS CON UN TEST SET QUE TENGA EL MISMO NUMERO DE APTs Y MALWARE")
##Pasamos de valores 0 o 1 a valores true or false:
#Y_test_equal=(YequalSet == 1)
#
#
###Y luego lo calculamos con la funcion de sklearn predict:
#y_test_equal_pred=cross_val_predict(forest_clf, XequalSet, Y_test_equal, cv=10)
#
###Calculamos el porcentaje de aciertos. Primero lo hacemos a mano...
#YY=YequalSet.values
#acierto=0
#total=0
#for i in range(0,400):
#        total=total+1
#        ej=XequalSet[i]
#        prediction=forest_clf.predict([ej])
#
#        if (prediction) and YY[i]==1:
#                acierto=acierto + 1
#        if (not prediction) and YY[i]==0:
#                acierto=acierto + 1
#media=0.0
#media=100.0*acierto / total*1.0
#print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"
#
#
#print "%porcentaje de acierto....", cross_val_score(forest_clf, XequalSet, Y_test_equal, cv=10, scoring="accuracy")*100
#
#
############
## Confusion Matrix
############
#
#print "\nConfusion Matrix"
#print confusion_matrix(Y_test_equal,y_test_equal_pred)
#
#print "\nPrecision Score:"
#print precision_score(Y_test_equal,y_test_equal_pred)
#print "\nRecall Score:"
#print recall_score(Y_test_equal,y_test_equal_pred)
#
#
############
## ROC AUC Score
############
#from sklearn.metrics import roc_auc_score
#y_scores_forest=y_probabilities_forest[:,1]
#
#print "\nROC AUC Score"
#print roc_auc_score(Y_train_APT, y_scores_forest)
#
#
############
## Classification Report
############
#from sklearn.metrics import classification_report
#print(classification_report(Y_test_equal, y_test_equal_pred, target_names=["Malware","APT"]))
#



#########################################################################################################################
# ROC Curve # # Esta grafica nos permite decidir cual de los clasificadores son mejores
########################################################################################################################

#Aqui Obtenemos probabilidades, a partir de los sets de training de cada clase
#y_probabilities_forest=cross_val_predict(forest_clf, X_train, Y_train_APT, cv=10, method="predict_proba")

#Esto devuelve un array del tipo( Probabilidades de que si, probabilidades de que no):
#[[1.  0. ]
# [1.  0. ]
# ...
# [0.7 0.3]
# [0.6 0.4]
# [0.  1. ]]

print "\nROC Curve"
fig = plt.figure(figsize=(14, 14))

##############
# En esta curva prueba los clasificadores fiteados en la primera parte contra el nuevo Train Set (Realmente los probamos contra el test set del nuevo dataset)
##############

#######RANDOM FOREST########
y_probabilities_forest=cross_val_predict(forest_clf, X_total, Y_total_APT, cv=10, method="predict_proba")
y_scores_forest=y_probabilities_forest[:,1]
fpr_forest, tpr_forest, threshold_forest=roc_curve(Y_total_APT,y_scores_forest)
roc_auc = auc(fpr_forest, tpr_forest)
plt.plot(fpr_forest, tpr_forest, linewidth=2, label='Roc Curve de Random Forest Classifier (area= %0.4f)' % roc_auc)
#
#######DECISSION TREE########
y_probabilities_decission=cross_val_predict(tree_clf, X_total, Y_total_APT, cv=10, method="predict_proba")
y_scores_decission=y_probabilities_decission[:,1]
fpr_decission, tpr_decission, threshold_decission=roc_curve(Y_total_APT,y_scores_decission)
roc_auc = auc(fpr_decission, tpr_decission)
plt.plot(fpr_decission, tpr_decission, linewidth=2, label='Roc Curve de Decission Tree Classifier (area= %0.4f)' % roc_auc)

#######SVM########
y_probabilities_svm=cross_val_predict(svm_clf, X_total, Y_total_APT, cv=10,method="predict_proba")
y_scores_svm=y_probabilities_svm[:,1]
fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_total_APT,y_scores_svm)
roc_auc = auc(fpr_svm, tpr_svm)
plt.plot(fpr_svm, tpr_svm, linewidth=2, label='Roc Curve de SVC (area= %0.4f)' % roc_auc)
#
#######KNN########
y_probabilities_knn=cross_val_predict(knn_clf, X_total, Y_total_APT, cv=10, method="predict_proba")
y_scores_knn=y_probabilities_knn[:,1]
fpr_knn, tpr_knn, threshold_knn=roc_curve(Y_total_APT,y_scores_knn)
roc_auc = auc(fpr_knn, tpr_knn)
plt.plot(fpr_knn, tpr_knn, linewidth=2, label='Roc Curve de KNN(area = %0.4f)' % roc_auc)

######LOGISTIC REGRESSION########
y_probabilities_lr=cross_val_predict(lr_clf, X_total, Y_total_APT, cv=10, method="predict_proba")
y_scores_lr=y_probabilities_lr[:,1]
fpr_lr, tpr_lr, threshold_lr = roc_curve(Y_total_APT, y_scores_lr)
roc_auc = auc(fpr_lr, tpr_lr)
plt.plot(fpr_lr, tpr_lr, linewidth=2, label='Roc Curve de Logistic Regression (area= %0.4f)' % roc_auc)

######PAINT IT!!########

fig.tight_layout()
plt.plot([0,1],[0,1],"k--")
plt.axis([0,1,0,1])
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")
plt.title("PROBABILITIES with previously trained classifiers")
plt.legend()
plt.show()
plt.savefig('resultados/Roc_Curve_With_Previously_trained_clssifiers.png', bbox_inches='tight')



#########################################################################################################################
# ROC Curve  with owndata#
########################################################################################################################

print "\nROC Curve with own data"
fig = plt.figure(figsize=(15, 15))
#
#######RANDOM FOREST########
y_probabilities_forest=cross_val_predict(forest_clf_owndata, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_forest=y_probabilities_forest[:,1]
fpr_forest, tpr_forest, threshold_forest=roc_curve(Y_test_APT,y_scores_forest)
roc_auc = auc(fpr_forest, tpr_forest)
plt.plot(fpr_forest, tpr_forest, linewidth=2, label='Roc Curve de Random Forest Classifier (area= %0.4f)' % roc_auc)
#
#######DECISSION TREE########
y_probabilities_decission=cross_val_predict(tree_clf_owndata, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_decission=y_probabilities_decission[:,1]
fpr_decission, tpr_decission, threshold_decission=roc_curve(Y_test_APT,y_scores_decission)
roc_auc = auc(fpr_decission, tpr_decission)
plt.plot(fpr_decission, tpr_decission, linewidth=2, label='Roc Curve de Decission Tree Classifier (area= %0.4f)' % roc_auc)
#
#######SVC########
y_probabilities_svm=cross_val_predict(svm_clf_owndata, X_test, Y_test_APT, cv=10,method="predict_proba")
y_scores_svm=y_probabilities_svm[:,1]
fpr_svm, tpr_svm, threshold_svm=roc_curve(Y_test_APT,y_scores_svm)
roc_auc = auc(fpr_svm, tpr_svm)
plt.plot(fpr_svm, tpr_svm, linewidth=2, label='Roc Curve de SVC (area= %0.4f)' % roc_auc)
#
#######KNN########
y_probabilities_knn=cross_val_predict(knn_clf_owndata, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_knn=y_probabilities_knn[:,1]
fpr_knn, tpr_knn, threshold_knn=roc_curve(Y_test_APT,y_scores_knn)
roc_auc = auc(fpr_knn, tpr_knn)
plt.plot(fpr_knn, tpr_knn, linewidth=2, label='Roc Curve de KNN(area = %0.4f)' % roc_auc)
#
######LOGISTIC REGRESSION########
y_probabilities_lr=cross_val_predict(lr_clf_owndata, X_test, Y_test_APT, cv=10, method="predict_proba")
y_scores_lr=y_probabilities_lr[:,1]
fpr_lr, tpr_lr, threshold_lr = roc_curve(Y_test_APT, y_scores_lr)
roc_auc = auc(fpr_lr, tpr_lr)
plt.plot(fpr_lr, tpr_lr, linewidth=2, label='Roc Curve de Logistic Regression (area= %0.4f)' % roc_auc)
#
######PAINT IT!!########
#
fig.tight_layout()
plt.plot([0,1],[0,1],"k--")
plt.axis([0,1,0,1])
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")
plt.title("PROBABILITIES")
plt.legend()
plt.show()
plt.savefig('resultados/Roc_Curve_With_Only_NewData_Classified.png', bbox_inches='tight')

