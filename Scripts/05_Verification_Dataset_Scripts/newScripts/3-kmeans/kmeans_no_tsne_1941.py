import numpy as np
from numpy import *
from time import time
import pandas as pd
import sys
from time import time
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn import manifold
from sklearn.manifold import TSNE
from sklearn.cluster import AffinityPropagation
from sklearn.cluster import MeanShift, estimate_bandwidth
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.cluster import AgglomerativeClustering
from sklearn.neighbors import kneighbors_graph
import time

##########
#FICHEROS#
##########
input_file= "../datasets/reducido_a_1941_features_without_NaNs_y_19457_rows.csv"
data_dir="../tmp"
tmp_file="../tmp/dataset_1941.joblib.pkl"
data_filename = data_dir + '/tsne_1941_3D_f.npy'
output_file='resultados/kmeans_pre_TSNE_2_groups_1941.png'

##########
#ARGUMENTS#
##########
print "Current input/output values are:"
print "         Input File:"+input_file
print "         TMP File:"+tmp_file
print "         Output File:"+output_file
print

start = time.time()
##################################
# PREPARATIVOS
##################################

###Leemos el dataset
df = pd.read_csv(input_file, header = 0, sep=';', dtype={"MD5":object,"FIRST_SEEN":object,"SIZE":int,"NUM_PACKERS":float64,"PACKERS_BIN":float64,"PACKERS_BIN_DIST":float64,"MALWARE_TYPE":object,"NUM_IMPORTS":float64,"IMPORTS_BIN":float64,"IMPORTS_BINARY_DIST":float64,"HAS_OVERLAYS":int,"SUSPICIOUS_DLLS":float64,"SUSPICIOUS_DLLS_DIST":float64,"ANTIDEBUG_BINARY":float64,"ANTIDEBUG_BINARY_DIST":float64,"NUM_LANG":float64,"LANG_BINARY":float64,"LANG_BINARY_DIST":float64,"API_BINARY":float64,"API_BINARY_DIST":float64,"RESOURCE_NUM":int,"SERVICES_BINARY":float64,"SERVICES_BINARY_DIST":float64,"all_files_binary":float64,"all_files_binary_DIST":float64,"all_opened_files_binary":float64,"all_opened_files_binary_DIST":float64,"all_written_files_binary":float64,"all_written_files_binary_DIST":float64,"all_deleted_files_binary":float64,"all_deleted_files_binary_DIST":float64,"all_read_files_binary":float64,"all_read_files_binary_DIST":float64,"UDP_Countries":float64,"UDP_Countries_DIST":float64,"TCP_countries":float64,"TCP_countries_DIST":float64,"DNS_countries":float64,"DNS_countries_DIST":float64,"SSDEEP":int,"IMPHASH":int,"APT":int,"NUM_APT":int})

###Separamos los campos que no nos interesan y campos objetivo
apttypes=df.APT
numapt=df.NUM_APT
#md5=df.MD5

###Quitamos las cabeceras de los campos objetivo
isAPT=apttypes.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

print isAPT.shape

end = time.time()
print(end - start)

print df.shape

##################################
# Standarization
##################################
print ("Standarization process...")
end = time.time()
print(end - start)
start = time.time()
from sklearn import preprocessing
X = preprocessing.scale(df)

##################################
# KMEANS
##################################
print ("Kmeans process...")
end = time.time()
print(end - start)
###Creamos la figura
fig = plt.figure(figsize=(15, 15))
n_clusters_=2
reduced_data=X


#print (values4)

##############################################################
###Calculamos el DBSCAN:
#dbsc = DBSCANI(eps=4, min_samples=200).fit(reduced_data)
#core_samples_mask = np.zeros_like(dbsc.labels_, dtype=bool)
#core_samples_mask[dbsc.core_sample_indices_] = True
#labels = dbsc.labels_
#labels_true=isAPT		
##
### Number of clusters in labels, ignoring noise if present.
#n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
#n_noise_ = list(labels).count(-1)
###
#print('Estimated number of clusters: %d' % n_clusters_)
#print('Estimated number of noise points: %d' % n_noise_)
#print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
#print("Completeness: %0.3f" % metrics.completeness_score(labels_true, labels))
#print("V-measure: %0.3f" % metrics.v_measure_score(labels_true, labels))
#print("Adjusted Rand Index: %0.3f" % metrics.adjusted_rand_score(labels_true, labels))
#print("Adjusted Mutual Information: %0.3f" % metrics.adjusted_mutual_info_score(labels_true, labels))
#print("Silhouette Coefficient: %0.3f" % metrics.silhouette_score(reduced_data, labels))

exit()

##############################################################
#kmeans = AgglomerativeClustering(linkage='average', connectivity=None, n_clusters=2)
#kmeans.fit(reduced_data)

for eps_ in [0.2, 0.3, 0.6, 1,2, 4, 8, 12, 24, 48, 96]:
	for min_samples_ in [25, 50, 75, 100, 200, 400, 600]:
		db=DBSCAN(eps=eps_, min_samples=min_samples_). fit(reduced_data)
		core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
		core_samples_mask[db.core_sample_indices_] = True
		labels = db.labels_
		n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
		n_noise_ = list(labels).count(-1)

		print ("PARA EPS=%f y MIN_SIZE=%d, salen %d clusters:" , eps_, min_samples_, n_clusters_)
		
		if (n_clusters_ > 0):
			print('Estimated number of clusters: %d' % n_clusters_)
			print('Estimated number of noise points: %d' % n_noise_)
			print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
			print("Completeness: %0.3f" % metrics.completeness_score(labels_true, labels))
			print("V-measure: %0.3f" % metrics.v_measure_score(labels_true, labels))
			print("Adjusted Rand Index: %0.3f" % metrics.adjusted_rand_score(labels_true, labels))

exit()

###Calculamos el KNN:
kmeans = KMeans(n_clusters=n_clusters_,n_init=10, max_iter=300, tol=1e-04, random_state=0).fit(reduced_data)

df3=pd.DataFrame(data=reduced_data)
print(df3)

print ("###############################")
print ("Kmeans predicting...")
end = time.time()
print(end - start)
predict=kmeans.predict(reduced_data)
df3['estimated_cluster']=pd.Series(predict, index=df3.index)
values4=pd.Series(predict, index=df3.index)

print ("###############################")
print ("Calculando TSNE...")
end = time.time()
print(end - start)

tsne = manifold.TSNE(n_components=3, perplexity=30)
Y = tsne.fit_transform(reduced_data)
np.save(data_filename, Y)

print ("Pintando...")
end = time.time()
print(end - start)
###Pintamos los clusters
ax = fig.add_subplot(111, projection='3d')

#ax.scatter(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:,2], cmap=plt.cm.Spectral, s=2, c=kmeans.labels_.astype(float))
ax.scatter(Y[:, 0], Y[:, 1], Y[:,2], cmap=plt.cm.Spectral, s=2, c=values4)

###Y pintamos los centroides
#centroids = kmeans.cluster_centers_
#ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:,2],marker='x', s=169, linewidths=3, color='black', zorder=10)
#plt.title("Kmeans with %s groups" % (num+1) );
plt.title('Estimated number of clusters: %d' % n_clusters_)


##################################
# SHOW PLOT
##################################
#ax.xaxis.set_major_formatter(NullFormatter())
#ax.yaxis.set_major_formatter(NullFormatter())
plt.axis('tight')
fig.savefig(output_file)
plt.show()
