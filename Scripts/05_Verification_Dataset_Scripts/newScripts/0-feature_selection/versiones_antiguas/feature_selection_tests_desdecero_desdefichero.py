##################################
# IMPORTS
##################################
import numpy as np
from numpy import *
import pandas as pd
from time import time
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn import manifold
from sklearn.manifold import TSNE
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn import datasets
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.externals import joblib 
import sys
import numpy
##################################
# PREPARATIVOS
##################################

###Leemos el dataset
#input_file="../datasets/csv_a_empezar_desde_cero_v2_sin_cols21y37_con52_y_49_46_y43_40_34_31_28_24_17_14_10_final_con_cabecera_quitamos_5_muestras.csv"
input_file="../datasets/csv_a_empezar_desde_cero_v2_sin_cols21y37_con52_y_49_46_y43_40_34_31_28_24_17_14_10_final_con_cabecera_quitamos_5_muestras_develgroup_country_new_headers.csv"

df = pd.read_csv(input_file, header = 0, sep=';', dtype={"MD5":object,"FIRST_SEEN":object,"SIZE":int,"NUM_PACKERS":float64,"PACKERS_BIN":float64,"PACKERS_BIN_DIST":float64,"MALWARE_TYPE":object,"NUM_IMPORTS":float64,"IMPORTS_BIN":float64,"IMPORTS_BINARY_DIST":float64,"HAS_OVERLAYS":int,"SUSPICIOUS_DLLS":float64,"SUSPICIOUS_DLLS_DIST":float64,"ANTIDEBUG_BINARY":float64,"ANTIDEBUG_BINARY_DIST":float64,"NUM_LANG":float64,"LANG_BINARY":float64,"LANG_BINARY_DIST":float64,"API_BINARY":float64,"API_BINARY_DIST":float64,"RESOURCE_NUM":int,"SERVICES_BINARY":float64,"SERVICES_BINARY_DIST":float64,"all_files_binary":float64,"all_files_binary_DIST":float64,"all_opened_files_binary":float64,"all_opened_files_binary_DIST":float64,"all_written_files_binary":float64,"all_written_files_binary_DIST":float64,"all_deleted_files_binary":float64,"all_deleted_files_binary_DIST":float64,"all_read_files_binary":float64,"all_read_files_binary_DIST":float64,"UDP_Countries":float64,"UDP_Countries_DIST":float64,"TCP_countries":float64,"TCP_countries_DIST":float64,"DNS_countries":float64,"DNS_countries_DIST":float64,"SSDEEP":int,"IMPHASH":int,"APT":int,"NUM_APT":int})

#Quitamos el SSDEEP pq dice que tiene campos nulos
#df = pd.read_csv(input_file, header = 0, sep=';', dtype={"MD5":object,"FIRST_SEEN":object,"SIZE":int,"NUM_PACKERS":float64,"PACKERS_BIN":float64,"PACKERS_BIN_DIST":float64,"MALWARE_TYPE":object,"NUM_IMPORTS":float64,"IMPORTS_BIN":float64,"IMPORTS_BINARY_DIST":float64,"HAS_OVERLAYS":int,"SUSPICIOUS_DLLS":float64,"SUSPICIOUS_DLLS_DIST":float64,"ANTIDEBUG_BINARY":float64,"ANTIDEBUG_BINARY_DIST":float64,"NUM_LANG":float64,"LANG_BINARY":float64,"LANG_BINARY_DIST":float64,"API_BINARY":float64,"API_BINARY_DIST":float64,"RESOURCE_NUM":int,"SERVICES_BINARY":float64,"SERVICES_BINARY_DIST":float64,"all_files_binary":float64,"all_files_binary_DIST":float64,"all_opened_files_binary":float64,"all_opened_files_binary_DIST":float64,"all_written_files_binary":float64,"all_written_files_binary_DIST":float64,"all_deleted_files_binary":float64,"all_deleted_files_binary_DIST":float64,"all_read_files_binary":float64,"all_read_files_binary_DIST":float64,"UDP_Countries":float64,"UDP_Countries_DIST":float64,"TCP_countries":float64,"TCP_countries_DIST":float64,"DNS_countries":float64,"DNS_countries_DIST":float64})


###Separamos los campos que no nos interesan y campos objetivo
malwaretypes=df.MALWARE_TYPE
isapt=df.APT
numapt=df.NUM_APT

###Quitamos las cabeceras de los campos objetivo
values=malwaretypes.values.astype(np.int64)
values2=isapt.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

import datetime
def convert_to_year(date_in_some_format):
	datetime_object = datetime.datetime.strptime(date_in_some_format, '%d/%m/%Y %H:%M')
	totalmins=(datetime_object-datetime.datetime(1970,1,1)).total_seconds()/60
	return int(totalmins)

df['DATE'] = df['FIRST_SEEN'].apply(convert_to_year)
#print (df['Date'])

del df['FIRST_SEEN']

###Quitamos los campos que no nos interesan
#del df['MALWARE_TYPE']
del df['APT']
del df['MD5']
del df['NUM_APT']
del df['DEVEL_GROUP']
del df['DEVEL_COUNTRY']
del df['IMPHASH']
del df['SSDEEP']

####Quitamos los campos DIST
del df['PACKERS_BIN_DIST']
del df['IMPORTS_BINARY_DIST']
del df['ANTIDEBUG_BINARY_DIST']
del df['LANG_BINARY_DIST']
del df['API_BINARY_DIST']
del df['SERVICES_BINARY_DIST']
del df['all_files_binary_DIST']
del df['all_opened_files_binary_DIST']
del df['all_written_files_binary_DIST']
del df['all_deleted_files_binary_DIST']
del df['all_read_files_binary_DIST']
del df['UDP_Countries_DIST']
del df['TCP_countries_DIST']
del df['DNS_countries_DIST']
del df['SUSPICIOUS_DLLS_DIST']

del df['PACKERS_BIN']
del df['IMPORTS_BIN']
del df['ANTIDEBUG_BINARY']
del df['LANG_BINARY']
del df['API_BINARY']
del df['SERVICES_BINARY']
del df['all_files_binary']
del df['all_opened_files_binary']
del df['all_written_files_binary']
del df['all_deleted_files_binary']
del df['all_read_files_binary']
del df['UDP_Countries']
del df['TCP_countries']
del df['DNS_countries']
del df['SUSPICIOUS_DLLS']

del df['UNKNOWN1']
del df['UNKNOWN2']
del df['UNKNOWN3']
del df['UNKNOWN4']
del df['UNKNOWN5']
del df['UNKNOWN6']
del df['UNKNOWN7']
del df['UNKNOWN8']
del df['UNKNOWN9']
del df['UNKNOWN10']
del df['UNKNOWN11']
del df['UNKNOWN12']
del df['UNKNOWN13']
del df['UNKNOWN15']
del df['UNKNOWN16']

#df=df[:40]
#df=df.iloc[:,1215:1225]

numpy.set_printoptions(threshold=numpy.nan)
##################################
# IMPUTAMOS VALORES VACIOS
##################################
#X=joblib.load("../tmp/dataset_limpiado.joblib.pkl",  mmap_mode='r')
#X=joblib.load("../tmp/dataset_mas_completo_sin_imphash2.joblib.pkl",  mmap_mode='r')

from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy="most_frequent")
X=imp.fit_transform(df)

joblib.dump(X, "../tmp/dataset_mas_completo_sin_imphash_sin_ssdeeP.joblib.pkl")
#exit()

##################################
# FEATURE SELECTION
##################################
print("===================================================")
print("====Remove features with low variance (>0,9)=======")
print("===================================================")
Sel=VarianceThreshold(threshold=.9 * (1- .9))
fitt=Sel.fit(X)
New_X=Sel.fit_transform(X)
print df.shape
print X.shape

headers=list(df)
headersArray=array(array(headers))

print headersArray.shape
print("Son estos:")

scores=np.column_stack((headersArray,fitt.get_support()))
mat_sort = scores[scores[:,1].argsort()]
print(mat_sort)
joblib.dump(mat_sort, "../tmp/scores_varianza.pkl", compress=9)

##################################
# CHI2
##################################
#print(" ")
#print("====================================================")
#print("====Univariate Feature Selection (Chi2, k=10)=======")
#print("====================================================")

#kk=SelectKBest(chi2,2).fit(X,values2)
#New_X=SelectKBest(chi2,2).fit_transform(X,values2)

#print("==Los scores de cada campo son==")
#print(kk.scores_)
#scores=np.column_stack((headersArray,kk.scores_))
#mat_sort = scores[scores[:,1].astype(np.float).argsort()]
#print(mat_sort)
#print(" ")

##################################
# EXTRA TREE IMPORTANCES
##################################
print("=================================")
print("====Extra Tree importances=======")
print("=================================")
print("Usando el clasificador Extra Tree")

model=ExtraTreesClassifier()
#model.fit(df,values2)
model.fit(X,values2)
scores=np.column_stack((headersArray,model.feature_importances_))
mat_sort = scores[scores[:,1].astype(np.float).argsort()]
print(mat_sort)

##################################
# DECISION TREE IMPORTANCES
##################################
print("=================================")
print("====Decission Tree classifier====")
print("=================================")
print("Usando el clasificador Decission Tree")
from sklearn import tree

model=tree.DecisionTreeClassifier()
#model.fit(df,values2)
model.fit(X,values2)
scores=np.column_stack((headersArray,model.feature_importances_))

mat_sort = scores[scores[:,1].astype(np.float).argsort()]
print(mat_sort)

