import numpy as np
from numpy import *
import pandas as pd
from time import time

from sklearn.externals import joblib
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler

from sklearn import manifold

from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from matplotlib.colors import ListedColormap

from scipy.spatial import Voronoi, voronoi_plot_2d
def Polygon_Area(corners):
    n = len(corners)
    area = 0.0
    for i in range(n):
        j = (i + 1) % n
        area += corners[i][0] * corners[j][1]
        area -= corners[j][0] * corners[i][1]
    area = abs(area) / 2.0
    return area

input_file = "../datasets/csv_con_puntos_y_con_num_APTs_final_final_conptoycoma_new_3.csv"

df = pd.read_csv(input_file, header = 0, sep=';', dtype={"MD5":object,"FIRST_SEEN":object,"SIZE":int,"NUM_PACKERS":float64,"PACKERS_BIN":float64,"PACKERS_BIN_DIST":float64,"MALWARE_TYPE":object,"NUM_IMPORTS":float64,"IMPORTS_BIN":float64,"IMPORTS_BINARY_DIST":float64,"HAS_OVERLAYS":int,"SUSPICIOUS_DLLS":float64,"SUSPICIOUS_DLLS_DIST":float64,"ANTIDEBUG_BINARY":float64,"ANTIDEBUG_BINARY_DIST":float64,"NUM_LANG":float64,"LANG_BINARY":float64,"LANG_BINARY_DIST":float64,"API_BINARY":float64,"API_BINARY_DIST":float64,"RESOURCE_NUM":int,"SERVICES_BINARY":float64,"SERVICES_BINARY_DIST":float64,"all_files_binary":float64,"all_files_binary_DIST":float64,"all_opened_files_binary":float64,"all_opened_files_binary_DIST":float64,"all_written_files_binary":float64,"all_written_files_binary_DIST":float64,"all_deleted_files_binary":float64,"all_deleted_files_binary_DIST":float64,"all_read_files_binary":float64,"all_read_files_binary_DIST":float64,"UDP_Countries":float64,"UDP_Countries_DIST":float64,"TCP_countries":float64,"TCP_countries_DIST":float64,"DNS_countries":float64,"DNS_countries_DIST":float64,"SSDEEP":int,"IMPHASH":int,"APT":int,"NUM_APT":int})


##################################################
#Extraemos los campos 'objetivo' y los que no nos interesan
##################################################

malwaretypes=df.MALWARE_TYPE
ssdeeptypes=df.SSDEEP
imphashtypes=df.IMPHASH
isapt=df.APT
numapt=df.NUM_APT

values=malwaretypes.values.astype(np.int64)
values2=isapt.values.astype(np.int64)
values3=numapt.values.astype(np.int64)

#del df['MALWARE_TYPE']
del df['APT']
del df['MD5']
del df['FIRST_SEEN']
del df['SSDEEP']
del df['IMPHASH']
del df['NUM_APT']

############################################
# ELIMINAMOS LOS CAMPOS CON ALTA CORRELACION
############################################
#del df['IMPORTS_BINARY_DIST']
#del df['all_opened_files_binary_DIST']
#del df['all_read_files_binary_DIST']
#del df['all_files_binary_DIST']
#del df['SUSPICIOUS_DLLS_DIST']
#del df['all_written_files_binary_DIST']
#del df['all_deleted_files_binary_DIST']
#del df['NUM_IMPORTS']
#del df['NUM_PACKERS']
#del df['PACKERS_BIN_DIST']
#del df['LANG_BINARY_DIST']
#del df['API_BINARY_DIST']

##################################
# Preparando Training y Testing sets
##################################
#
#Barajamos las muestras. Realmente lo que se barajan son los indices.
shuffle_index=np.random.permutation(17000)

#Nos quedamos con los valores, descartando las cabeceras
df3=df.values
df=df.values

#X_train son las 17000 primeras muestras. X_test son las 3547 ultimas muestras
#Y_train es un 0 o un 1 por cada una de esas 17000 muestras indicando si se trata de un APT o no
#Y_test es un 0 o un 1 por cada una de esas 3547 muestras indicando si se trata de un APT o no
X_train,X_test,Y_train,Y_test=df[:17000],df[17000:],isapt[:17000],isapt[17000:]

#Calculamos un test set con el mismo numero de malware que de APTs
total=200
numAPT=0
numMAL=0
XequalSet=[]
YequalSet=pd.Series()
numTotal=1
for i in range(1,20547):
	if numAPT<total and isapt[i]==1:
		a=np.array(df[i])
		XequalSet.append(a)
		YequalSet = YequalSet.set_value(numTotal, isapt[i])
		numAPT+=1
		numTotal+=1
		
	if numMAL<total and isapt[i]==0:
		a=np.array(df[i])
		XequalSet.append(a)
		YequalSet = YequalSet.set_value(numTotal, isapt[i])
		numMAL+=1
		numTotal+=1

	if numAPT>=total and numMAL>=total:
		break

XequalSet = np.array(XequalSet)


###########################################
# TARGET VECTORS
###########################################
#Pasamos de valores 0 o 1 a valores true or false:
Y_train_APT=(Y_train == 1)
Y_test_APT=(Y_test == 1)

###########################################
# Gaussian RBF
###########################################

output_dir="../tmp"
output_filename = output_dir + '/tsne_nuevo.npy'

#En X tenemos los puntos del TSNE (2 dimensiones)
X = np.load(output_filename)
X = StandardScaler().fit_transform(X)
#X=X[:300]

#En Y tenemos si es una APT o no
Y=values2
#Y=values2[:300]
ax = plt.subplot(1,1,1)

vor = Voronoi(X)
regions=vor.regions
vertices=vor.vertices
# compute Voronoi tesselation

# plot

# colorize
colors=['#EF7D7D','#7DEF7D']
j=0
arearoja=0
areaverde=0
k=0
cm_bright = ListedColormap(['#FF0000', '#5DCF5D'])
for region in vor.regions:
    if region and not -1 in region and k<vor.point_region.size:
        polygon = [vor.vertices[i] for i in region]

	j=np.where(vor.point_region==k)[0][0]
    	c=Y[j]
	if (Y[j]==0):
		arearoja += Polygon_Area(polygon)
	else:
		areaverde += Polygon_Area(polygon)
    	plt.fill(*zip(*polygon), color=colors[c], edgecolor=None, linewidth=None, zorder=1)
    k=k+1

print("Area roja: "+str(arearoja))
print("Area verde: "+str(areaverde))


plt.xlim(vor.min_bound[0] - 0.1, vor.max_bound[0] + 0.1)
plt.ylim(vor.min_bound[1] - 0.1, vor.max_bound[1] + 0.1)
ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=cm_bright,s=1, zorder=10)
plt.show()
plt.savefig('voro2.png')
#fig = voronoi_plot_2d(vor, show_vertices=False, show_points=False)
#ax=fig.axes[0]
#ax.set_title("Voronoi")
#
#cm_bright = ListedColormap(['#FF0000', '#00FF00'])
#ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=cm_bright,s=1)

#for region in vor.regions:
#    if not -1 in region:
#        polygon = [vor.vertices[i] for i in region]
#        plt.fill(*zip(*polygon))
#
#plt.savefig('resultados/voronoi.png')
#plt.show()


exit()

##########################################
# KNN
###########################################
from sklearn import tree
from sklearn import svm
from sklearn import neighbors, datasets

clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
clf.fit(X_train, Y_train_APT)

    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, x_max]x[y_min, y_max].
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

#Creamos el clasificador. El random_state value no deberia afectar
#tree_clf = tree.DecisionTreeClassifier()
tree_clf = neighbors.KNeighborsClassifier(3)

#Y lo entrenamos con el training Set
tree_clf.fit(X_train, Y_train_APT)

##Calculamos (A mano) el porcentaje de aciertos. Lo hacemos con los valores del test set
acierto=0
total=0
for i in range(17000,20547):
	total=total+1
	ej=df3[i]
	prediction=tree_clf.predict([ej])

	#print i, prediction, isapt[i]
	if (prediction) and isapt[i]==1:
		acierto=acierto + 1
	if (not prediction) and isapt[i]==0:
		acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"


##Y ahora hacemos la prediccion con la funcion de sklearn predict:
#y_test_pred=cross_val_predict(tree_clf, X_test, Y_test_APT, cv=3)
y_test_pred=cross_val_predict(tree_clf, X_test, Y_test_APT)

#En y_test_pred se ha almacenado el array de predicciones

print "\nCross Validation de SKLEARN. Lo intentamos con 7 foldings:"
print "%porcentaje de acierto....", cross_val_score(tree_clf, X_test, Y_test_APT, cv=7, scoring="accuracy")*100



###########
# Confusion Matrix
###########
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

print "\nConfusion Matrix"
print confusion_matrix(Y_test_APT,y_test_pred)

print "\nPrecision Score:"
print precision_score(Y_test_APT,y_test_pred) 
print "\nRecall Score:"
print recall_score(Y_test_APT,y_test_pred) 


#########
# ROC Curve
#
# Esta grafica nos permite decidir cual de los clasificadores son mejores
###########
from sklearn.metrics import roc_curve

#Aqui Obtenemos probabilidades, a partir de los sets de training de cada clase
y_probabilities_tree=cross_val_predict(tree_clf, X_train, Y_train_APT, cv=3, method="predict_proba")

#Esto devuelve un array del tipo( Probabilidades de que si, probabilidades de que no):
#[[1.  0. ]
# [1.  0. ]
# ...
# [0.7 0.3]
# [0.6 0.4]
# [0.  1. ]]

print "\nROC Curve"
fig = plt.figure(figsize=(15, 15))
y_scores_tree=y_probabilities_tree[:,1]
fpr_tree, tpr_tree, threshold_tree=roc_curve(Y_train_APT,y_scores_tree)


plt.plot(fpr_tree, tpr_tree, linewidth=2, label=None)
plt.plot([0,1],[0,1],"k--")
plt.axis([0,1,0,1])
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")
plt.legend()
plt.show()
plt.savefig('resultados/Roc_Curve_With_DecissionTree.png')

###########
# ROC AUC (Area under Curve) Score
###########
from sklearn.metrics import roc_auc_score

print "\nROC AUC Score"
print roc_auc_score(Y_train_APT, y_scores_tree)


###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_APT, y_test_pred, target_names=["Malware","APT"]))






###########################################
# AHORA INTENTAMOS CON UN TEST SET QUE TENGA EL MISMO NUMERO DE APTs Y MALWARE
###########################################
#Pasamos de valores 0 o 1 a valores true or false:
Y_test_equal=(YequalSet == 1)

###########################################
# Decission Tree Classifier
###########################################

###
##Y luego lo calculamos con la funcion de sklearn predict:
y_test_equal_pred=cross_val_predict(tree_clf, XequalSet, Y_test_equal, cv=3)

##Calculamos el porcentaje de aciertos. Primero lo hacemos a mano...
YY=YequalSet.values
acierto=0
total=0
for i in range(0,400):
	total=total+1
	ej=XequalSet[i]
	prediction=tree_clf.predict([ej])

	if (prediction) and YY[i]==1:
		acierto=acierto + 1
	if (not prediction) and YY[i]==0:
		acierto=acierto + 1
media=0.0
media=100.0*acierto / total*1.0
print "\n",acierto," aciertos de ",total,"intentos (",media,"%)"




###########
# Confusion Matrix
###########

print "\nConfusion Matrix"
print confusion_matrix(Y_test_equal,y_test_equal_pred)

print "\nPrecision Score:"
print precision_score(Y_test_equal,y_test_equal_pred) 
print "\nRecall Score:"
print recall_score(Y_test_equal,y_test_equal_pred) 


###########
# ROC AUC Score
###########
from sklearn.metrics import roc_auc_score
y_scores_tree=y_probabilities_tree[:,1]

print "\nROC AUC Score"
print roc_auc_score(Y_train_APT, y_scores_tree)


###########
# Classification Report
###########
from sklearn.metrics import classification_report
print(classification_report(Y_test_equal, y_test_equal_pred, target_names=["Malware","APT"]))
